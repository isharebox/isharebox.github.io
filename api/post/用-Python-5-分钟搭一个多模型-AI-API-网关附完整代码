{"content":"{\"__ud_title\":\"用 Python 5 分钟搭一个多模型 AI API 网关（附完整代码）\",\"__ud_tags\":[\"ai\",\"python\"],\"__ud_update_time\":1770713015302,\"__ud_create_time\":1770708607476,\"__ud_draft\":false,\"type\":\"doc\",\"content\":[{\"type\":\"heading\",\"attrs\":{\"level\":1,\"id\":\"用-Python-5-分钟搭一个多模型-AI-API-网关附完整代码\"},\"content\":[{\"type\":\"text\",\"text\":\"用 Python 5 分钟搭一个多模型 AI API 网关（附完整代码）\"}]},{\"type\":\"blockquote\",\"content\":[{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"还在手动切换 OpenAI、Claude、DeepSeek 的 API？用 Python 搭一个统一的 AI 网关，一个接口调所有模型，自动故障转移，代码不到 100 行。\"}]}]},{\"type\":\"heading\",\"attrs\":{\"level\":2,\"id\":\"为什么需要-AI-API-网关\"},\"content\":[{\"type\":\"text\",\"text\":\"为什么需要 AI API 网关？\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"如果你在做 AI 应用开发，大概率遇到过这些问题：\"}]},{\"type\":\"bulletList\",\"content\":[{\"type\":\"listItem\",\"content\":[{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"OpenAI 抽风了，服务挂了 2 小时，你的应用跟着挂\"}]}]},{\"type\":\"listItem\",\"content\":[{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"DeepSeek 发布新版本，API 过载，请求全超时\"}]}]},{\"type\":\"listItem\",\"content\":[{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"老板突然说\\\"我们试试 Claude\\\"，你得改一堆代码\"}]}]},{\"type\":\"listItem\",\"content\":[{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"不同模型的 API 格式不一样，适配起来头疼\"}]}]}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"这些问题的本质是：你的应用直接耦合了某个具体的模型 API。\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"解决方案很简单——在你的应用和模型之间加一层网关，统一接口、自动路由、故障转移。\"}]},{\"type\":\"heading\",\"attrs\":{\"level\":2,\"id\":\"完整代码100-行的-AI-网关\"},\"content\":[{\"type\":\"text\",\"text\":\"完整代码：100 行的 AI 网关\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"直接上代码，Python + FastAPI，能跑的那种。\"}]},{\"type\":\"codeBlock\",\"attrs\":{\"language\":null},\"content\":[{\"type\":\"text\",\"text\":\"import os\\nimport time\\nimport httpx\\nimport asyncio\\nfrom fastapi import FastAPI, Request\\nfrom fastapi.responses import JSONResponse\\n\\napp = FastAPI(title=\\\"AI API Gateway\\\")\\n\\n# 模型配置：按优先级排列\\nMODEL_PROVIDERS = [\\n    {\\n        \\\"name\\\": \\\"deepseek\\\",\\n        \\\"base_url\\\": \\\"https://api.deepseek.com/v1\\\",\\n        \\\"api_key\\\": os.getenv(\\\"DEEPSEEK_API_KEY\\\", \\\"\\\"),\\n        \\\"model\\\": \\\"deepseek-chat\\\",\\n        \\\"timeout\\\": 30,\\n        \\\"max_retries\\\": 2,\\n    },\\n    {\\n        \\\"name\\\": \\\"openai\\\",\\n        \\\"base_url\\\": \\\"https://api.openai.com/v1\\\",\\n        \\\"api_key\\\": os.getenv(\\\"OPENAI_API_KEY\\\", \\\"\\\"),\\n        \\\"model\\\": \\\"gpt-4o-mini\\\",\\n        \\\"timeout\\\": 30,\\n        \\\"max_retries\\\": 1,\\n    },\\n    {\\n        \\\"name\\\": \\\"anthropic\\\",\\n        \\\"base_url\\\": \\\"https://api.anthropic.com/v1\\\",\\n        \\\"api_key\\\": os.getenv(\\\"ANTHROPIC_API_KEY\\\", \\\"\\\"),\\n        \\\"model\\\": \\\"claude-3-5-sonnet-20241022\\\",\\n        \\\"timeout\\\": 30,\\n        \\\"max_retries\\\": 1,\\n    },\\n]\\n\\n# 健康状态追踪\\nprovider_health = {p[\\\"name\\\"]: {\\\"healthy\\\": True, \\\"last_fail\\\": 0} for p in MODEL_PROVIDERS}\\nCOOLDOWN_SECONDS = 60  # 故障冷却时间\\n\\n\\nasync def call_provider(provider: dict, messages: list) -> dict:\\n    \\\"\\\"\\\"调用单个模型供应商\\\"\\\"\\\"\\n    headers = {\\n        \\\"Authorization\\\": f\\\"Bearer {provider['api_key']}\\\",\\n        \\\"Content-Type\\\": \\\"application/json\\\",\\n    }\\n\\n    # Anthropic 的 API 格式略有不同\\n    if provider[\\\"name\\\"] == \\\"anthropic\\\":\\n        headers = {\\n            \\\"x-api-key\\\": provider[\\\"api_key\\\"],\\n            \\\"anthropic-version\\\": \\\"2023-06-01\\\",\\n            \\\"Content-Type\\\": \\\"application/json\\\",\\n        }\\n        payload = {\\n            \\\"model\\\": provider[\\\"model\\\"],\\n            \\\"max_tokens\\\": 4096,\\n            \\\"messages\\\": messages,\\n        }\\n        url = f\\\"{provider['base_url']}/messages\\\"\\n    else:\\n        payload = {\\n            \\\"model\\\": provider[\\\"model\\\"],\\n            \\\"messages\\\": messages,\\n            \\\"max_tokens\\\": 4096,\\n        }\\n        url = f\\\"{provider['base_url']}/chat/completions\\\"\\n\\n    async with httpx.AsyncClient(timeout=provider[\\\"timeout\\\"]) as client:\\n        resp = await client.post(url, json=payload, headers=headers)\\n        resp.raise_for_status()\\n        return resp.json()\\n\\n\\ndef normalize_response(provider_name: str, raw: dict) -> dict:\\n    \\\"\\\"\\\"统一不同供应商的响应格式\\\"\\\"\\\"\\n    if provider_name == \\\"anthropic\\\":\\n        content = raw.get(\\\"content\\\", [{}])[0].get(\\\"text\\\", \\\"\\\")\\n        model = raw.get(\\\"model\\\", \\\"\\\")\\n    else:\\n        content = raw[\\\"choices\\\"][0][\\\"message\\\"][\\\"content\\\"]\\n        model = raw.get(\\\"model\\\", \\\"\\\")\\n\\n    return {\\n        \\\"content\\\": content,\\n        \\\"model\\\": model,\\n        \\\"provider\\\": provider_name,\\n    }\\n\\n\\n@app.post(\\\"/v1/chat\\\")\\nasync def chat(request: Request):\\n    \\\"\\\"\\\"统一聊天接口——自动路由到可用的模型\\\"\\\"\\\"\\n    body = await request.json()\\n    messages = body.get(\\\"messages\\\", [])\\n    preferred = body.get(\\\"provider\\\", None)  # 可选：指定供应商\\n\\n    errors = []\\n\\n    for provider in MODEL_PROVIDERS:\\n        name = provider[\\\"name\\\"]\\n        health = provider_health[name]\\n\\n        # 跳过指定供应商以外的\\n        if preferred and name != preferred:\\n            continue\\n\\n        # 跳过冷却中的供应商\\n        if not health[\\\"healthy\\\"] and time.time() - health[\\\"last_fail\\\"] < COOLDOWN_SECONDS:\\n            continue\\n\\n        try:\\n            raw = await call_provider(provider, messages)\\n            provider_health[name][\\\"healthy\\\"] = True\\n            return JSONResponse(normalize_response(name, raw))\\n\\n        except Exception as e:\\n            provider_health[name] = {\\\"healthy\\\": False, \\\"last_fail\\\": time.time()}\\n            errors.append(f\\\"{name}: {str(e)}\\\")\\n            continue\\n\\n    return JSONResponse(\\n        {\\\"error\\\": \\\"All providers failed\\\", \\\"details\\\": errors},\\n        status_code=503,\\n    )\\n\\n\\n@app.get(\\\"/health\\\")\\nasync def health():\\n    \\\"\\\"\\\"查看各供应商健康状态\\\"\\\"\\\"\\n    return {name: info for name, info in provider_health.items()}\\n\"}]},{\"type\":\"heading\",\"attrs\":{\"level\":2,\"id\":\"怎么用\"},\"content\":[{\"type\":\"text\",\"text\":\"怎么用\"}]},{\"type\":\"heading\",\"attrs\":{\"level\":3,\"id\":\"1-安装依赖\"},\"content\":[{\"type\":\"text\",\"text\":\"1. 安装依赖\"}]},{\"type\":\"codeBlock\",\"attrs\":{\"language\":null},\"content\":[{\"type\":\"text\",\"text\":\"  pip install fastapi uvicorn httpx\\n\"}]},{\"type\":\"heading\",\"attrs\":{\"level\":3,\"id\":\"2-设置-API-Key\"},\"content\":[{\"type\":\"text\",\"text\":\"2. 设置 API Key\"}]},{\"type\":\"codeBlock\",\"attrs\":{\"language\":\"bash\"},\"content\":[{\"type\":\"text\",\"text\":\"export DEEPSEEK_API_KEY=\\\"sk-xxx\\\"\\nexport OPENAI_API_KEY=\\\"sk-xxx\\\"\\nexport ANTHROPIC_API_KEY=\\\"sk-xxx\\\"\\n\"}]},{\"type\":\"heading\",\"attrs\":{\"level\":3,\"id\":\"3-启动\"},\"content\":[{\"type\":\"text\",\"text\":\"3. 启动\"}]},{\"type\":\"codeBlock\",\"attrs\":{\"language\":\"bash\"},\"content\":[{\"type\":\"text\",\"text\":\"uvicorn gateway:app --port 8000\\n\"}]},{\"type\":\"heading\",\"attrs\":{\"level\":3,\"id\":\"4-调用\"},\"content\":[{\"type\":\"text\",\"text\":\"4. 调用\"}]},{\"type\":\"codeBlock\",\"attrs\":{\"language\":\"bash\"},\"content\":[{\"type\":\"text\",\"text\":\"# 自动路由（优先 DeepSeek，失败自动切换）\\ncurl -X POST http://localhost:8000/v1/chat \\\\\\n  -H \\\"Content-Type: application/json\\\" \\\\\\n  -d '{\\\"messages\\\": [{\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"你好\\\"}]}'\\n\\n# 指定供应商\\ncurl -X POST http://localhost:8000/v1/chat \\\\\\n  -H \\\"Content-Type: application/json\\\" \\\\\\n  -d '{\\\"messages\\\": [{\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"你好\\\"}], \\\"provider\\\": \\\"openai\\\"}'\\n\\n# 查看健康状态\\ncurl http://localhost:8000/health\\n\"}]},{\"type\":\"heading\",\"attrs\":{\"level\":2,\"id\":\"核心设计思路\"},\"content\":[{\"type\":\"text\",\"text\":\"核心设计思路\"}]},{\"type\":\"heading\",\"attrs\":{\"level\":3,\"id\":\"1-优先级路由\"},\"content\":[{\"type\":\"text\",\"text\":\"1. 优先级路由\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"marks\":[{\"type\":\"code\"}],\"text\":\"MODEL_PROVIDERS\"},{\"type\":\"text\",\"text\":\" 数组的顺序就是优先级。DeepSeek 排第一是因为性价比最高，OpenAI 和 Claude 作为备用。\"}]},{\"type\":\"heading\",\"attrs\":{\"level\":3,\"id\":\"2-自动故障转移\"},\"content\":[{\"type\":\"text\",\"text\":\"2. 自动故障转移\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"某个供应商报错后，标记为\\\"不健康\\\"并进入 60 秒冷却期。在此期间跳过该供应商，直接尝试下一个。冷却结束后自动恢复。\"}]},{\"type\":\"heading\",\"attrs\":{\"level\":3,\"id\":\"3-响应格式统一\"},\"content\":[{\"type\":\"text\",\"text\":\"3. 响应格式统一\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"不管后端用的是哪个模型，返回格式都是统一的 \"},{\"type\":\"text\",\"marks\":[{\"type\":\"code\"}],\"text\":\"{content, model, provider}\"},{\"type\":\"text\",\"text\":\"，调用方完全不需要关心底层用的是谁。\"}]},{\"type\":\"heading\",\"attrs\":{\"level\":2,\"id\":\"进阶优化方向\"},\"content\":[{\"type\":\"text\",\"text\":\"进阶优化方向\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"这个 100 行版本是最小可用版。生产环境中你可能还需要：\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"功能说明流式响应SSE 支持，实现打字机效果请求日志记录每次请求的模型、耗时、token 数成本追踪按 token 计费，统计各模型花费负载均衡多个 API Key 轮询，避免单 Key 限流缓存层相同请求命中缓存，省钱又快鉴权给网关加 API Key，防止滥用\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"如果你不想自己造轮子，市面上也有现成的模型聚合方案：\"}]},{\"type\":\"bulletList\",\"content\":[{\"type\":\"listItem\",\"content\":[{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"OpenRouter\"},{\"type\":\"text\",\"text\":\"：国外主流，模型多，但国内访问不稳定\"}]}]},{\"type\":\"listItem\",\"content\":[{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"marks\":[{\"type\":\"link\",\"attrs\":{\"href\":\"http://Ofox.ai\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer nofollow\",\"class\":null}},{\"type\":\"bold\"}],\"text\":\"Ofox.ai\"},{\"type\":\"text\",\"text\":\"：国内可直接用，支持主流模型，适合国内开发者\"}]}]},{\"type\":\"listItem\",\"content\":[{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"One-API / New-API\"},{\"type\":\"text\",\"text\":\"：开源自建方案，需要自己部署维护\"}]}]}]},{\"type\":\"heading\",\"attrs\":{\"level\":2,\"id\":\"总结\"},\"content\":[{\"type\":\"text\",\"text\":\"总结\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"搭一个 AI API 网关并不难，核心就三件事：\"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"统一接口、自动路由、故障转移\"},{\"type\":\"text\",\"text\":\"。\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"100 行代码就能解决 90% 的场景。剩下的 10%（流式、缓存、监控），要么自己加，要么用现成的聚合平台。\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"重点是：\"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"别让你的应用跟任何一个模型供应商绑死\"},{\"type\":\"text\",\"text\":\"。保持灵活。\"}]}]}","title":"用 Python 5 分钟搭一个多模型 AI API 网关（附完整代码）","tags":["ai","python"],"updateTime":1770713015302,"createTime":1770708607476,"draft":false,"intro":"如果你在做 AI 应用开发，大概率遇到过这些问题：","html":"<h1 level=\"1\" id=\"用-Python-5-分钟搭一个多模型-AI-API-网关附完整代码\">用 Python 5 分钟搭一个多模型 AI API 网关（附完整代码）</h1><blockquote><p>还在手动切换 OpenAI、Claude、DeepSeek 的 API？用 Python 搭一个统一的 AI 网关，一个接口调所有模型，自动故障转移，代码不到 100 行。</p></blockquote><h2 level=\"2\" id=\"为什么需要-AI-API-网关\">为什么需要 AI API 网关？</h2><p>如果你在做 AI 应用开发，大概率遇到过这些问题：</p><ul><li><p>OpenAI 抽风了，服务挂了 2 小时，你的应用跟着挂</p></li><li><p>DeepSeek 发布新版本，API 过载，请求全超时</p></li><li><p>老板突然说&quot;我们试试 Claude&quot;，你得改一堆代码</p></li><li><p>不同模型的 API 格式不一样，适配起来头疼</p></li></ul><p><strong>这些问题的本质是：你的应用直接耦合了某个具体的模型 API。</strong></p><p>解决方案很简单——在你的应用和模型之间加一层网关，统一接口、自动路由、故障转移。</p><h2 level=\"2\" id=\"完整代码100-行的-AI-网关\">完整代码：100 行的 AI 网关</h2><p>直接上代码，Python + FastAPI，能跑的那种。</p><div class=\"llt-code readonly\"><div class=\"language\">python</div><div class=\"wrapper\"><pre><code><span class=\"hljs-keyword\" class=\"hljs-keyword\">import</span> os\n<span class=\"hljs-keyword\" class=\"hljs-keyword\">import</span> time\n<span class=\"hljs-keyword\" class=\"hljs-keyword\">import</span> httpx\n<span class=\"hljs-keyword\" class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\" class=\"hljs-keyword\">from</span> fastapi <span class=\"hljs-keyword\" class=\"hljs-keyword\">import</span> FastAPI, Request\n<span class=\"hljs-keyword\" class=\"hljs-keyword\">from</span> fastapi.responses <span class=\"hljs-keyword\" class=\"hljs-keyword\">import</span> JSONResponse\n\napp = FastAPI(title=<span class=\"hljs-string\" class=\"hljs-string\">&quot;AI API Gateway&quot;</span>)\n\n<span class=\"hljs-comment\" class=\"hljs-comment\"># 模型配置：按优先级排列</span>\nMODEL_PROVIDERS = [\n    {\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;name&quot;</span>: <span class=\"hljs-string\" class=\"hljs-string\">&quot;deepseek&quot;</span>,\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;base_url&quot;</span>: <span class=\"hljs-string\" class=\"hljs-string\">&quot;https://api.deepseek.com/v1&quot;</span>,\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;api_key&quot;</span>: os.getenv(<span class=\"hljs-string\" class=\"hljs-string\">&quot;DEEPSEEK_API_KEY&quot;</span>, <span class=\"hljs-string\" class=\"hljs-string\">&quot;&quot;</span>),\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;model&quot;</span>: <span class=\"hljs-string\" class=\"hljs-string\">&quot;deepseek-chat&quot;</span>,\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;timeout&quot;</span>: <span class=\"hljs-number\" class=\"hljs-number\">30</span>,\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;max_retries&quot;</span>: <span class=\"hljs-number\" class=\"hljs-number\">2</span>,\n    },\n    {\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;name&quot;</span>: <span class=\"hljs-string\" class=\"hljs-string\">&quot;openai&quot;</span>,\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;base_url&quot;</span>: <span class=\"hljs-string\" class=\"hljs-string\">&quot;https://api.openai.com/v1&quot;</span>,\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;api_key&quot;</span>: os.getenv(<span class=\"hljs-string\" class=\"hljs-string\">&quot;OPENAI_API_KEY&quot;</span>, <span class=\"hljs-string\" class=\"hljs-string\">&quot;&quot;</span>),\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;model&quot;</span>: <span class=\"hljs-string\" class=\"hljs-string\">&quot;gpt-4o-mini&quot;</span>,\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;timeout&quot;</span>: <span class=\"hljs-number\" class=\"hljs-number\">30</span>,\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;max_retries&quot;</span>: <span class=\"hljs-number\" class=\"hljs-number\">1</span>,\n    },\n    {\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;name&quot;</span>: <span class=\"hljs-string\" class=\"hljs-string\">&quot;anthropic&quot;</span>,\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;base_url&quot;</span>: <span class=\"hljs-string\" class=\"hljs-string\">&quot;https://api.anthropic.com/v1&quot;</span>,\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;api_key&quot;</span>: os.getenv(<span class=\"hljs-string\" class=\"hljs-string\">&quot;ANTHROPIC_API_KEY&quot;</span>, <span class=\"hljs-string\" class=\"hljs-string\">&quot;&quot;</span>),\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;model&quot;</span>: <span class=\"hljs-string\" class=\"hljs-string\">&quot;claude-3-5-sonnet-20241022&quot;</span>,\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;timeout&quot;</span>: <span class=\"hljs-number\" class=\"hljs-number\">30</span>,\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;max_retries&quot;</span>: <span class=\"hljs-number\" class=\"hljs-number\">1</span>,\n    },\n]\n\n<span class=\"hljs-comment\" class=\"hljs-comment\"># 健康状态追踪</span>\nprovider_health = {p[<span class=\"hljs-string\" class=\"hljs-string\">&quot;name&quot;</span>]: {<span class=\"hljs-string\" class=\"hljs-string\">&quot;healthy&quot;</span>: <span class=\"hljs-literal\" class=\"hljs-literal\">True</span>, <span class=\"hljs-string\" class=\"hljs-string\">&quot;last_fail&quot;</span>: <span class=\"hljs-number\" class=\"hljs-number\">0</span>} <span class=\"hljs-keyword\" class=\"hljs-keyword\">for</span> p <span class=\"hljs-keyword\" class=\"hljs-keyword\">in</span> MODEL_PROVIDERS}\nCOOLDOWN_SECONDS = <span class=\"hljs-number\" class=\"hljs-number\">60</span>  <span class=\"hljs-comment\" class=\"hljs-comment\"># 故障冷却时间</span>\n\n\n<span class=\"hljs-keyword\" class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\" class=\"hljs-keyword\">def</span> <span class=\"hljs-title,function_\" class=\"hljs-title,function_\">call_provider</span>(<span class=\"hljs-params\" class=\"hljs-params\">provider: <span class=\"hljs-built_in\" class=\"hljs-built_in\">dict</span>, messages: <span class=\"hljs-built_in\" class=\"hljs-built_in\">list</span></span>) -&gt; <span class=\"hljs-built_in\" class=\"hljs-built_in\">dict</span>:\n    <span class=\"hljs-string\" class=\"hljs-string\">&quot;&quot;&quot;调用单个模型供应商&quot;&quot;&quot;</span>\n    headers = {\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;Authorization&quot;</span>: <span class=\"hljs-string\" class=\"hljs-string\">f&quot;Bearer <span class=\"hljs-subst\" class=\"hljs-subst\">{provider[<span class=\"hljs-string\" class=\"hljs-string\">&apos;api_key&apos;</span>]}</span>&quot;</span>,\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;Content-Type&quot;</span>: <span class=\"hljs-string\" class=\"hljs-string\">&quot;application/json&quot;</span>,\n    }\n\n    <span class=\"hljs-comment\" class=\"hljs-comment\"># Anthropic 的 API 格式略有不同</span>\n    <span class=\"hljs-keyword\" class=\"hljs-keyword\">if</span> provider[<span class=\"hljs-string\" class=\"hljs-string\">&quot;name&quot;</span>] == <span class=\"hljs-string\" class=\"hljs-string\">&quot;anthropic&quot;</span>:\n        headers = {\n            <span class=\"hljs-string\" class=\"hljs-string\">&quot;x-api-key&quot;</span>: provider[<span class=\"hljs-string\" class=\"hljs-string\">&quot;api_key&quot;</span>],\n            <span class=\"hljs-string\" class=\"hljs-string\">&quot;anthropic-version&quot;</span>: <span class=\"hljs-string\" class=\"hljs-string\">&quot;2023-06-01&quot;</span>,\n            <span class=\"hljs-string\" class=\"hljs-string\">&quot;Content-Type&quot;</span>: <span class=\"hljs-string\" class=\"hljs-string\">&quot;application/json&quot;</span>,\n        }\n        payload = {\n            <span class=\"hljs-string\" class=\"hljs-string\">&quot;model&quot;</span>: provider[<span class=\"hljs-string\" class=\"hljs-string\">&quot;model&quot;</span>],\n            <span class=\"hljs-string\" class=\"hljs-string\">&quot;max_tokens&quot;</span>: <span class=\"hljs-number\" class=\"hljs-number\">4096</span>,\n            <span class=\"hljs-string\" class=\"hljs-string\">&quot;messages&quot;</span>: messages,\n        }\n        url = <span class=\"hljs-string\" class=\"hljs-string\">f&quot;<span class=\"hljs-subst\" class=\"hljs-subst\">{provider[<span class=\"hljs-string\" class=\"hljs-string\">&apos;base_url&apos;</span>]}</span>/messages&quot;</span>\n    <span class=\"hljs-keyword\" class=\"hljs-keyword\">else</span>:\n        payload = {\n            <span class=\"hljs-string\" class=\"hljs-string\">&quot;model&quot;</span>: provider[<span class=\"hljs-string\" class=\"hljs-string\">&quot;model&quot;</span>],\n            <span class=\"hljs-string\" class=\"hljs-string\">&quot;messages&quot;</span>: messages,\n            <span class=\"hljs-string\" class=\"hljs-string\">&quot;max_tokens&quot;</span>: <span class=\"hljs-number\" class=\"hljs-number\">4096</span>,\n        }\n        url = <span class=\"hljs-string\" class=\"hljs-string\">f&quot;<span class=\"hljs-subst\" class=\"hljs-subst\">{provider[<span class=\"hljs-string\" class=\"hljs-string\">&apos;base_url&apos;</span>]}</span>/chat/completions&quot;</span>\n\n    <span class=\"hljs-keyword\" class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\" class=\"hljs-keyword\">with</span> httpx.AsyncClient(timeout=provider[<span class=\"hljs-string\" class=\"hljs-string\">&quot;timeout&quot;</span>]) <span class=\"hljs-keyword\" class=\"hljs-keyword\">as</span> client:\n        resp = <span class=\"hljs-keyword\" class=\"hljs-keyword\">await</span> client.post(url, json=payload, headers=headers)\n        resp.raise_for_status()\n        <span class=\"hljs-keyword\" class=\"hljs-keyword\">return</span> resp.json()\n\n\n<span class=\"hljs-keyword\" class=\"hljs-keyword\">def</span> <span class=\"hljs-title,function_\" class=\"hljs-title,function_\">normalize_response</span>(<span class=\"hljs-params\" class=\"hljs-params\">provider_name: <span class=\"hljs-built_in\" class=\"hljs-built_in\">str</span>, raw: <span class=\"hljs-built_in\" class=\"hljs-built_in\">dict</span></span>) -&gt; <span class=\"hljs-built_in\" class=\"hljs-built_in\">dict</span>:\n    <span class=\"hljs-string\" class=\"hljs-string\">&quot;&quot;&quot;统一不同供应商的响应格式&quot;&quot;&quot;</span>\n    <span class=\"hljs-keyword\" class=\"hljs-keyword\">if</span> provider_name == <span class=\"hljs-string\" class=\"hljs-string\">&quot;anthropic&quot;</span>:\n        content = raw.get(<span class=\"hljs-string\" class=\"hljs-string\">&quot;content&quot;</span>, [{}])[<span class=\"hljs-number\" class=\"hljs-number\">0</span>].get(<span class=\"hljs-string\" class=\"hljs-string\">&quot;text&quot;</span>, <span class=\"hljs-string\" class=\"hljs-string\">&quot;&quot;</span>)\n        model = raw.get(<span class=\"hljs-string\" class=\"hljs-string\">&quot;model&quot;</span>, <span class=\"hljs-string\" class=\"hljs-string\">&quot;&quot;</span>)\n    <span class=\"hljs-keyword\" class=\"hljs-keyword\">else</span>:\n        content = raw[<span class=\"hljs-string\" class=\"hljs-string\">&quot;choices&quot;</span>][<span class=\"hljs-number\" class=\"hljs-number\">0</span>][<span class=\"hljs-string\" class=\"hljs-string\">&quot;message&quot;</span>][<span class=\"hljs-string\" class=\"hljs-string\">&quot;content&quot;</span>]\n        model = raw.get(<span class=\"hljs-string\" class=\"hljs-string\">&quot;model&quot;</span>, <span class=\"hljs-string\" class=\"hljs-string\">&quot;&quot;</span>)\n\n    <span class=\"hljs-keyword\" class=\"hljs-keyword\">return</span> {\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;content&quot;</span>: content,\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;model&quot;</span>: model,\n        <span class=\"hljs-string\" class=\"hljs-string\">&quot;provider&quot;</span>: provider_name,\n    }\n\n\n<span class=\"hljs-meta\" class=\"hljs-meta\">@app.post(<span class=\"hljs-params\" class=\"hljs-params\"><span class=\"hljs-string\" class=\"hljs-string\">&quot;/v1/chat&quot;</span></span>)</span>\n<span class=\"hljs-keyword\" class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\" class=\"hljs-keyword\">def</span> <span class=\"hljs-title,function_\" class=\"hljs-title,function_\">chat</span>(<span class=\"hljs-params\" class=\"hljs-params\">request: Request</span>):\n    <span class=\"hljs-string\" class=\"hljs-string\">&quot;&quot;&quot;统一聊天接口——自动路由到可用的模型&quot;&quot;&quot;</span>\n    body = <span class=\"hljs-keyword\" class=\"hljs-keyword\">await</span> request.json()\n    messages = body.get(<span class=\"hljs-string\" class=\"hljs-string\">&quot;messages&quot;</span>, [])\n    preferred = body.get(<span class=\"hljs-string\" class=\"hljs-string\">&quot;provider&quot;</span>, <span class=\"hljs-literal\" class=\"hljs-literal\">None</span>)  <span class=\"hljs-comment\" class=\"hljs-comment\"># 可选：指定供应商</span>\n\n    errors = []\n\n    <span class=\"hljs-keyword\" class=\"hljs-keyword\">for</span> provider <span class=\"hljs-keyword\" class=\"hljs-keyword\">in</span> MODEL_PROVIDERS:\n        name = provider[<span class=\"hljs-string\" class=\"hljs-string\">&quot;name&quot;</span>]\n        health = provider_health[name]\n\n        <span class=\"hljs-comment\" class=\"hljs-comment\"># 跳过指定供应商以外的</span>\n        <span class=\"hljs-keyword\" class=\"hljs-keyword\">if</span> preferred <span class=\"hljs-keyword\" class=\"hljs-keyword\">and</span> name != preferred:\n            <span class=\"hljs-keyword\" class=\"hljs-keyword\">continue</span>\n\n        <span class=\"hljs-comment\" class=\"hljs-comment\"># 跳过冷却中的供应商</span>\n        <span class=\"hljs-keyword\" class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\" class=\"hljs-keyword\">not</span> health[<span class=\"hljs-string\" class=\"hljs-string\">&quot;healthy&quot;</span>] <span class=\"hljs-keyword\" class=\"hljs-keyword\">and</span> time.time() - health[<span class=\"hljs-string\" class=\"hljs-string\">&quot;last_fail&quot;</span>] &lt; COOLDOWN_SECONDS:\n            <span class=\"hljs-keyword\" class=\"hljs-keyword\">continue</span>\n\n        <span class=\"hljs-keyword\" class=\"hljs-keyword\">try</span>:\n            raw = <span class=\"hljs-keyword\" class=\"hljs-keyword\">await</span> call_provider(provider, messages)\n            provider_health[name][<span class=\"hljs-string\" class=\"hljs-string\">&quot;healthy&quot;</span>] = <span class=\"hljs-literal\" class=\"hljs-literal\">True</span>\n            <span class=\"hljs-keyword\" class=\"hljs-keyword\">return</span> JSONResponse(normalize_response(name, raw))\n\n        <span class=\"hljs-keyword\" class=\"hljs-keyword\">except</span> Exception <span class=\"hljs-keyword\" class=\"hljs-keyword\">as</span> e:\n            provider_health[name] = {<span class=\"hljs-string\" class=\"hljs-string\">&quot;healthy&quot;</span>: <span class=\"hljs-literal\" class=\"hljs-literal\">False</span>, <span class=\"hljs-string\" class=\"hljs-string\">&quot;last_fail&quot;</span>: time.time()}\n            errors.append(<span class=\"hljs-string\" class=\"hljs-string\">f&quot;<span class=\"hljs-subst\" class=\"hljs-subst\">{name}</span>: <span class=\"hljs-subst\" class=\"hljs-subst\">{<span class=\"hljs-built_in\" class=\"hljs-built_in\">str</span>(e)}</span>&quot;</span>)\n            <span class=\"hljs-keyword\" class=\"hljs-keyword\">continue</span>\n\n    <span class=\"hljs-keyword\" class=\"hljs-keyword\">return</span> JSONResponse(\n        {<span class=\"hljs-string\" class=\"hljs-string\">&quot;error&quot;</span>: <span class=\"hljs-string\" class=\"hljs-string\">&quot;All providers failed&quot;</span>, <span class=\"hljs-string\" class=\"hljs-string\">&quot;details&quot;</span>: errors},\n        status_code=<span class=\"hljs-number\" class=\"hljs-number\">503</span>,\n    )\n\n\n<span class=\"hljs-meta\" class=\"hljs-meta\">@app.get(<span class=\"hljs-params\" class=\"hljs-params\"><span class=\"hljs-string\" class=\"hljs-string\">&quot;/health&quot;</span></span>)</span>\n<span class=\"hljs-keyword\" class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\" class=\"hljs-keyword\">def</span> <span class=\"hljs-title,function_\" class=\"hljs-title,function_\">health</span>():\n    <span class=\"hljs-string\" class=\"hljs-string\">&quot;&quot;&quot;查看各供应商健康状态&quot;&quot;&quot;</span>\n    <span class=\"hljs-keyword\" class=\"hljs-keyword\">return</span> {name: info <span class=\"hljs-keyword\" class=\"hljs-keyword\">for</span> name, info <span class=\"hljs-keyword\" class=\"hljs-keyword\">in</span> provider_health.items()}\n</code></pre></div></div><h2 level=\"2\" id=\"怎么用\">怎么用</h2><h3 level=\"3\" id=\"1-安装依赖\">1. 安装依赖</h3><div class=\"llt-code readonly\"><div class=\"language\">auto</div><div class=\"wrapper\"><pre><code></code></pre></div></div><h3 level=\"3\" id=\"2-设置-API-Key\">2. 设置 API Key</h3><div class=\"llt-code readonly\"><div class=\"language\">bash</div><div class=\"wrapper\"><pre><code class=\"language-bash\"><span class=\"hljs-built_in\" class=\"hljs-built_in\">export</span> DEEPSEEK_API_KEY=<span class=\"hljs-string\" class=\"hljs-string\">&quot;sk-xxx&quot;</span>\n<span class=\"hljs-built_in\" class=\"hljs-built_in\">export</span> OPENAI_API_KEY=<span class=\"hljs-string\" class=\"hljs-string\">&quot;sk-xxx&quot;</span>\n<span class=\"hljs-built_in\" class=\"hljs-built_in\">export</span> ANTHROPIC_API_KEY=<span class=\"hljs-string\" class=\"hljs-string\">&quot;sk-xxx&quot;</span>\n</code></pre></div></div><h3 level=\"3\" id=\"3-启动\">3. 启动</h3><div class=\"llt-code readonly\"><div class=\"language\">bash</div><div class=\"wrapper\"><pre><code class=\"language-bash\">uvicorn gateway:app --port 8000\n</code></pre></div></div><h3 level=\"3\" id=\"4-调用\">4. 调用</h3><div class=\"llt-code readonly\"><div class=\"language\">bash</div><div class=\"wrapper\"><pre><code class=\"language-bash\"><span class=\"hljs-comment\" class=\"hljs-comment\"># 自动路由（优先 DeepSeek，失败自动切换）</span>\ncurl -X POST http://localhost:8000/v1/chat \\\n  -H <span class=\"hljs-string\" class=\"hljs-string\">&quot;Content-Type: application/json&quot;</span> \\\n  -d <span class=\"hljs-string\" class=\"hljs-string\">&apos;{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你好&quot;}]}&apos;</span>\n\n<span class=\"hljs-comment\" class=\"hljs-comment\"># 指定供应商</span>\ncurl -X POST http://localhost:8000/v1/chat \\\n  -H <span class=\"hljs-string\" class=\"hljs-string\">&quot;Content-Type: application/json&quot;</span> \\\n  -d <span class=\"hljs-string\" class=\"hljs-string\">&apos;{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你好&quot;}], &quot;provider&quot;: &quot;openai&quot;}&apos;</span>\n\n<span class=\"hljs-comment\" class=\"hljs-comment\"># 查看健康状态</span>\ncurl http://localhost:8000/health\n</code></pre></div></div><h2 level=\"2\" id=\"核心设计思路\">核心设计思路</h2><h3 level=\"3\" id=\"1-优先级路由\">1. 优先级路由</h3><p><code>MODEL_PROVIDERS</code> 数组的顺序就是优先级。DeepSeek 排第一是因为性价比最高，OpenAI 和 Claude 作为备用。</p><h3 level=\"3\" id=\"2-自动故障转移\">2. 自动故障转移</h3><p>某个供应商报错后，标记为&quot;不健康&quot;并进入 60 秒冷却期。在此期间跳过该供应商，直接尝试下一个。冷却结束后自动恢复。</p><h3 level=\"3\" id=\"3-响应格式统一\">3. 响应格式统一</h3><p>不管后端用的是哪个模型，返回格式都是统一的 <code>{content, model, provider}</code>，调用方完全不需要关心底层用的是谁。</p><h2 level=\"2\" id=\"进阶优化方向\">进阶优化方向</h2><p>这个 100 行版本是最小可用版。生产环境中你可能还需要：</p><p>功能说明流式响应SSE 支持，实现打字机效果请求日志记录每次请求的模型、耗时、token 数成本追踪按 token 计费，统计各模型花费负载均衡多个 API Key 轮询，避免单 Key 限流缓存层相同请求命中缓存，省钱又快鉴权给网关加 API Key，防止滥用</p><p>如果你不想自己造轮子，市面上也有现成的模型聚合方案：</p><ul><li><p><strong>OpenRouter</strong>：国外主流，模型多，但国内访问不稳定</p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"http://Ofox.ai\"><strong>Ofox.ai</strong></a>：国内可直接用，支持主流模型，适合国内开发者</p></li><li><p><strong>One-API / New-API</strong>：开源自建方案，需要自己部署维护</p></li></ul><h2 level=\"2\" id=\"总结\">总结</h2><p>搭一个 AI API 网关并不难，核心就三件事：<strong>统一接口、自动路由、故障转移</strong>。</p><p>100 行代码就能解决 90% 的场景。剩下的 10%（流式、缓存、监控），要么自己加，要么用现成的聚合平台。</p><p>重点是：<strong>别让你的应用跟任何一个模型供应商绑死</strong>。保持灵活。</p><script type=\"module\">const injectHtml = (root, html) => {\n  const iframe = document.createElement(\"iframe\");\n  const htmlContent = `<html><head></head><body>${html}</body></html>`;\n  iframe.style.width = \"100%\";\n  iframe.style.height = \"100%\";\n  iframe.onload = () => {\n    const doc = iframe.contentDocument || iframe.contentWindow?.document;\n    if (!doc) {\n      return;\n    }\n    doc.open();\n    doc.write(htmlContent);\n    doc.close();\n  };\n  root.replaceChildren(iframe);\n}\n  document.querySelectorAll('.playground')?.forEach(el=>{\n    const html = el.getAttribute('data-html');\n    if (html) {\n      injectHtml(el,html);\n    }\n    const indicator = document.createElement(\"div\");\n    indicator.className = \"indicator\";\n    const showCode = document.createElement(\"div\");\n    showCode.className = \"show-code\";\n    showCode.innerText = \"code\";\n    showCode.onclick = () => {\n      el.parentElement.classList.remove(\"preview-only\");\n    };\n    const showPreview = document.createElement(\"div\");\n    showPreview.className = \"show-preview\";\n    showPreview.innerText = \"preview\";\n    showPreview.onclick = () => {\n      el.parentElement.classList.add(\"preview-only\");\n    };\n    indicator.appendChild(showCode);\n    indicator.appendChild(showPreview);\n    el.parentElement.appendChild(indicator);\n    if (window.screen.width < 768) {\n      showPreview.click();\n    }\n  });</script>","id":"用-Python-5-分钟搭一个多模型-AI-API-网关附完整代码","path":"/posts/用-Python-5-分钟搭一个多模型-AI-API-网关附完整代码.json"}