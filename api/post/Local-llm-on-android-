{"content":"{\"__ud_title\":\"Local llm on android\",\"__ud_tags\":[\"model\"],\"__ud_update_time\":1771563440541,\"__ud_create_time\":1771562370091,\"__ud_draft\":false,\"type\":\"doc\",\"content\":[{\"type\":\"heading\",\"attrs\":{\"level\":1,\"id\":\"Local-llm-on-android-\"},\"content\":[{\"type\":\"text\",\"text\":\"Local llm on android\"}]},{\"type\":\"heading\",\"attrs\":{\"level\":3,\"id\":\"大模型方案评估\"},\"content\":[{\"type\":\"text\",\"text\":\"大模型方案评估\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"| 方案名称 | 可行性评估 | 具体分析与建议 |\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"| :--- | :--- | :--- |\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"| \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"MNN Chat\"},{\"type\":\"text\",\"text\":\" | ⭐⭐⭐ \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"最推荐\"},{\"type\":\"text\",\"text\":\" | 阿里这款App优化做得不错，对中端芯片友好。你可以在应用内直接下载针对手机优化过的小模型（如 \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"Qwen2.5-1.5B\"},{\"type\":\"text\",\"text\":\" 或 \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"4B\"},{\"type\":\"text\",\"text\":\" 的量化版），大概率能获得最流畅的开箱即用体验。 |\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"| \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"AnythingLLM Mobile\"},{\"type\":\"text\",\"text\":\" | ⭐⭐ \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"可以尝试\"},{\"type\":\"text\",\"text\":\" | 功能很强大，但运行本地知识库等操作对性能有一定要求。如果你的手机是**12GB内存版本**，可以尝试运行；如果是8GB版本，可能会出现资源紧张的情况。 |\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"| \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"Termux + llama.cpp\"},{\"type\":\"text\",\"text\":\" | ⭐⭐ \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"适合动手玩家\"},{\"type\":\"text\",\"text\":\" | 这条路完全走得通，能让你运行海量的GGUF模型。但需要你有心理准备去手动调整参数。建议从 \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"2B-4B\"},{\"type\":\"text\",\"text\":\" 参数量的模型（比如 \"},{\"type\":\"text\",\"marks\":[{\"type\":\"code\"}],\"text\":\"Phi-3-mini-4k-instruct\"},{\"type\":\"text\",\"text\":\" 的Q4量化版）开始尝试。 |\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"| \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"MNN + KleidiAI\"},{\"type\":\"text\",\"text\":\" | ⭐ \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"开发者专用\"},{\"type\":\"text\",\"text\":\" | 这是Arm官方的开发方案，是给应用开发者用来深度优化性能的，普通用户无需考虑。 |\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"| \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"Cactus / Qualcomm方案\"},{\"type\":\"text\",\"text\":\" | ⭐ \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"不太适合\"},{\"type\":\"text\",\"text\":\" | Cactus对普通用户不够友好。而高通的NPU方案主要针对骁龙芯片，你的天玑芯片无法直接利用其优势。 |\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"### 💡 给你的核心建议：从“小”开始\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"1. \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"优先看内存\"},{\"type\":\"text\",\"text\":\"：你的手机有8GB或12GB版本。8GB版建议选择参数量 \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"1.5B-4B\"},{\"type\":\"text\",\"text\":\" 的模型；12GB版则可以尝试 \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"7B\"},{\"type\":\"text\",\"text\":\" 参数量模型的 \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"超低量化版本\"},{\"type\":\"text\",\"text\":\"（如 \"},{\"type\":\"text\",\"marks\":[{\"type\":\"code\"}],\"text\":\"q2_k\"},{\"type\":\"text\",\"text\":\" 或 \"},{\"type\":\"text\",\"marks\":[{\"type\":\"code\"}],\"text\":\"q3_k\"},{\"type\":\"text\",\"text\":\" 版本）。\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"2. \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"认准GGUF和“Q”字头\"},{\"type\":\"text\",\"text\":\"：无论用哪个方案，在下载模型时，优先选择 \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"GGUF格式\"},{\"type\":\"text\",\"text\":\" 且文件名中带有 \"},{\"type\":\"text\",\"marks\":[{\"type\":\"code\"}],\"text\":\"Q4Q5\"},{\"type\":\"text\",\"text\":\" 等字样的文件。例如 \"},{\"type\":\"text\",\"marks\":[{\"type\":\"code\"}],\"text\":\"qwen2.5-1.5b-Q4_K_M.gguf\"},{\"type\":\"text\",\"text\":\"。这种格式是专门为在有限内存上高效运行而设计的。\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"3. \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"暂时忘掉7B以上的大模型\"},{\"type\":\"text\",\"text\":\"：像 Llama 3 8B、Qwen 2.5 7B 的常规版本，对你的手机来说负担太大，强行运行会很卡顿甚至闪退，体验不会太好。\"}]},{\"type\":\"paragraph\"},{\"type\":\"heading\",\"attrs\":{\"level\":3,\"id\":\"MNN-Chat它是由阿里巴巴开源的全功能多模态模型应用\"},\"content\":[{\"type\":\"text\",\"text\":\"MNN Chat，它是由阿里巴巴开源的全功能多模态模型应用。\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"marks\":[{\"type\":\"link\",\"attrs\":{\"href\":\"https://bgithub.xyz/alibaba/MNN/blob/master/apps/Android/MnnLlmChat/README.md#releases\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer nofollow\",\"class\":null}}],\"text\":\"https://bgithub.xyz/alibaba/MNN/blob/master/apps/Android/MnnLlmChat/README.md#releases\"},{\"type\":\"text\",\"text\":\"    \"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"仅需一台手机即可运行： 完全在设备本地运行，确保数据隐私，无需将信息上传至外部服务器。\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"    CPU 推理优化： 在安卓平台上，MNN-LLM 展现了卓越的 CPU 性能，预填充速度相较于 llama.cpp 提高了 8.6 倍，相较于 fastllm 提升了 20.5 倍，解码速度分别快了 2.3 倍和 8.9 倍。\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"    多模态支持： 提供多种任务功能，包括文本生成文本、图像生成文本、音频转文本及文本生成图像。\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"    广泛的模型兼容性： 支持多种领先的模型提供商，包括 Qwen、Gemma、Llama（涵盖 TinyLlama 与 MobileLLM）、Baichuan、Yi、DeepSeek、InternLM、Phi、ReaderLM 和 Smolm 等。\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"官网地址：\"},{\"type\":\"text\",\"marks\":[{\"type\":\"link\",\"attrs\":{\"href\":\"https://www.mnn.zone\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer nofollow\",\"class\":null}}],\"text\":\"https://www.mnn.zone\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"GitHub 源码地址：\"},{\"type\":\"text\",\"marks\":[{\"type\":\"link\",\"attrs\":{\"href\":\"https://github.com/alibaba/MNN\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer nofollow\",\"class\":null}}],\"text\":\"https://github.com/alibaba/MNN\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"marks\":[{\"type\":\"link\",\"attrs\":{\"href\":\"https://bgithub.xyz/alibaba/MNN\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer nofollow\",\"class\":null}}],\"text\":\"https://bgithub.xyz/alibaba/MNN\"}]},{\"type\":\"paragraph\"},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"1.安装 MNN 应用\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"对于 Android 手机，可以直接下载和安装最新版本：下载地址\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"MNN LLM \"},{\"type\":\"text\",\"marks\":[{\"type\":\"link\",\"attrs\":{\"href\":\"https://bgithub.xyz/alibaba/MNN/blob/master/apps/Android/MnnLlmChat/README.md#releases\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer nofollow\",\"class\":null}}],\"text\":\"https://bgithub.xyz/alibaba/MNN/blob/master/apps/Android/MnnLlmChat/README.md#releases\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"或者，我们也可以按照以下步骤，自己编译 Android 和 iOS 应用：\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"Android 编译和使用\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"    克隆 MNN 源代码：git clone \"},{\"type\":\"text\",\"marks\":[{\"type\":\"link\",\"attrs\":{\"href\":\"https://github.com/alibaba/MNN.git\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer nofollow\",\"class\":null}}],\"text\":\"https://github.com/alibaba/MNN.git\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"    构建库：\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"cd project/android\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"mkdir build_64\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"../build_\"},{\"type\":\"text\",\"marks\":[{\"type\":\"link\",\"attrs\":{\"href\":\"http://64.sh\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer nofollow\",\"class\":null}}],\"text\":\"64.sh\"},{\"type\":\"text\",\"text\":\" \\\"-DMNN_LOW_MEMORY=true -DMNN_CPU_WEIGHT_DEQUANT_GEMM=true -DMNN_BUILD_LLM=true -DMNN_SUPPORT_TRANSFORMER_FUSE=true -DMNN_ARM82=true -DMNN_USE_LOGCAT=true -DMNN_OPENCL=true -DLLM_SUPPORT_VISION=true -DMNN_BUILD_OPENCV=true -DMNN_IMGCODECS=true -DLLM_SUPPORT_AUDIO=true -DMNN_BUILD_AUDIO=true -DMNN_BUILD_DIFFUSION=ON -DMNN_SEP_BUILD=ON\\\"\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"    复制到 LLM Android 应用项目：\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"mkdir -p ../../../apps/Android/MnnLlmChat/app/src/main/jniLibs/arm64-v8a\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"find . -name \\\"*.so\\\" -exec cp {} ../../../apps/Android/MnnLlmChat/app/src/main/jniLibs/arm64-v8a \\\\;\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"    构建 Android 应用项目并安装：\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"cd ../../../apps/Android/MnnLlmChat\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"./gradlew installDebug\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"iOS 应用编译和使用\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"    克隆 MNN 源代码：git clone \"},{\"type\":\"text\",\"marks\":[{\"type\":\"link\",\"attrs\":{\"href\":\"https://github.com/alibaba/MNN.git\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer nofollow\",\"class\":null}}],\"text\":\"https://github.com/alibaba/MNN.git\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"    编译 MNN.framework:\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"cd MNN/\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"sh package_scripts/ios/\"},{\"type\":\"text\",\"marks\":[{\"type\":\"link\",\"attrs\":{\"href\":\"http://buildiOS.sh\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer nofollow\",\"class\":null}}],\"text\":\"buildiOS.sh\"},{\"type\":\"text\",\"text\":\" \\\"-DMNN_ARM82=true -DMNN_LOW_MEMORY=true -DMNN_SUPPORT_TRANSFORMER_FUSE=true -DMNN_BUILD_LLM=true -DMNN_CPU_WEIGHT_DEQUANT_GEMM=true\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"-DMNN_METAL=ON\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"-DMNN_BUILD_DIFFUSION=ON\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"-DMNN_BUILD_OPENCV=ON\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"-DMNN_IMGCODECS=ON\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"-DMNN_OPENCL=OFF\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"-DMNN_SEP_BUILD=OFF\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"-DMNN_SUPPORT_TRANSFORMER_FUSE=ON\\\"\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"    拷贝 framework 到 iOS 项目中：\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"mv MNN-iOS-CPU-GPU/Static/MNN.framework /apps/iOS/MNNLLMChat/MNN.framework\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"确保 Link Binary With Libraried 中包含 MNN.framework，和其他三个 Framework:\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"Framework\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"如果没有包含，可以手动添加 MNN.framework:\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"MNN.framework\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"    修改 iOS 签名并编译项目\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"cd /apps/iOS/MNNLLMChat\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"open MNNLLMiOS.xcodeproj\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"在 Xcode 项目属性中 Signing & Capabilities > Team 输入自己的账号和 Bundle Identifier:\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"签名\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"等待 Swift Package 下载完成之后，进行编译使用。\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"2.下载模型文件\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"手机上安装好MNN Chat应用之后，打开应用，就可以看到它所兼容的模型列表，包括文本、音频、图像等：\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"大模型列表\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"点击即可下载，想体验一下文本和图片识别，下载DeepSeek-R1-7B-Qwen-MNN和Qwen2-VL-2B-Instruct-MNN这 2 个大模型，等待下载完成。\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"3. MNN 模型推理\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"先试用一下DeepSeek-R1-7B-Qwen-MNN文本模型，输入提示词：\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"同样是一年，为什么阳历固定12个月，而阴历却有闰月？\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"DeepSeek文本推理\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"DeepSeek R1 开始思考，分析阳历和阴历的计算方法，最终得出结论：\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"DeepSeek思考结果\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"从手机的推理速率来看，总体还算不错，比通过Termux应用的方式推理效率高多了。\"}]},{\"type\":\"paragraph\"}]}","title":"Local llm on android","tags":["model"],"updateTime":1771563440541,"createTime":1771562370091,"draft":false,"intro":"| 方案名称 | 可行性评估 | 具体分析与建议 |","html":"<h1 level=\"1\" id=\"Local-llm-on-android\">Local llm on android</h1><h3 level=\"3\" id=\"大模型方案评估\">大模型方案评估</h3><p>| 方案名称 | 可行性评估 | 具体分析与建议 |</p><p>| :--- | :--- | :--- |</p><p>| <strong>MNN Chat</strong> | ⭐⭐⭐ <strong>最推荐</strong> | 阿里这款App优化做得不错，对中端芯片友好。你可以在应用内直接下载针对手机优化过的小模型（如 <strong>Qwen2.5-1.5B</strong> 或 <strong>4B</strong> 的量化版），大概率能获得最流畅的开箱即用体验。 |</p><p>| <strong>AnythingLLM Mobile</strong> | ⭐⭐ <strong>可以尝试</strong> | 功能很强大，但运行本地知识库等操作对性能有一定要求。如果你的手机是**12GB内存版本**，可以尝试运行；如果是8GB版本，可能会出现资源紧张的情况。 |</p><p>| <strong>Termux + llama.cpp</strong> | ⭐⭐ <strong>适合动手玩家</strong> | 这条路完全走得通，能让你运行海量的GGUF模型。但需要你有心理准备去手动调整参数。建议从 <strong>2B-4B</strong> 参数量的模型（比如 <code>Phi-3-mini-4k-instruct</code> 的Q4量化版）开始尝试。 |</p><p>| <strong>MNN + KleidiAI</strong> | ⭐ <strong>开发者专用</strong> | 这是Arm官方的开发方案，是给应用开发者用来深度优化性能的，普通用户无需考虑。 |</p><p>| <strong>Cactus / Qualcomm方案</strong> | ⭐ <strong>不太适合</strong> | Cactus对普通用户不够友好。而高通的NPU方案主要针对骁龙芯片，你的天玑芯片无法直接利用其优势。 |</p><p>### 💡 给你的核心建议：从“小”开始</p><p>1. <strong>优先看内存</strong>：你的手机有8GB或12GB版本。8GB版建议选择参数量 <strong>1.5B-4B</strong> 的模型；12GB版则可以尝试 <strong>7B</strong> 参数量模型的 <strong>超低量化版本</strong>（如 <code>q2_k</code> 或 <code>q3_k</code> 版本）。</p><p>2. <strong>认准GGUF和“Q”字头</strong>：无论用哪个方案，在下载模型时，优先选择 <strong>GGUF格式</strong> 且文件名中带有 <code>Q4Q5</code> 等字样的文件。例如 <code>qwen2.5-1.5b-Q4_K_M.gguf</code>。这种格式是专门为在有限内存上高效运行而设计的。</p><p>3. <strong>暂时忘掉7B以上的大模型</strong>：像 Llama 3 8B、Qwen 2.5 7B 的常规版本，对你的手机来说负担太大，强行运行会很卡顿甚至闪退，体验不会太好。</p><p></p><h3 level=\"3\" id=\"MNN-Chat它是由阿里巴巴开源的全功能多模态模型应用\">MNN Chat，它是由阿里巴巴开源的全功能多模态模型应用。</h3><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://bgithub.xyz/alibaba/MNN/blob/master/apps/Android/MnnLlmChat/README.md#releases\">https://bgithub.xyz/alibaba/MNN/blob/master/apps/Android/MnnLlmChat/README.md#releases</a>    </p><p>仅需一台手机即可运行： 完全在设备本地运行，确保数据隐私，无需将信息上传至外部服务器。</p><p>    CPU 推理优化： 在安卓平台上，MNN-LLM 展现了卓越的 CPU 性能，预填充速度相较于 llama.cpp 提高了 8.6 倍，相较于 fastllm 提升了 20.5 倍，解码速度分别快了 2.3 倍和 8.9 倍。</p><p>    多模态支持： 提供多种任务功能，包括文本生成文本、图像生成文本、音频转文本及文本生成图像。</p><p>    广泛的模型兼容性： 支持多种领先的模型提供商，包括 Qwen、Gemma、Llama（涵盖 TinyLlama 与 MobileLLM）、Baichuan、Yi、DeepSeek、InternLM、Phi、ReaderLM 和 Smolm 等。</p><p>官网地址：<a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.mnn.zone\">https://www.mnn.zone</a></p><p>GitHub 源码地址：<a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/alibaba/MNN\">https://github.com/alibaba/MNN</a></p><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://bgithub.xyz/alibaba/MNN\">https://bgithub.xyz/alibaba/MNN</a></p><p></p><p>1.安装 MNN 应用</p><p>对于 Android 手机，可以直接下载和安装最新版本：下载地址</p><p>MNN LLM <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://bgithub.xyz/alibaba/MNN/blob/master/apps/Android/MnnLlmChat/README.md#releases\">https://bgithub.xyz/alibaba/MNN/blob/master/apps/Android/MnnLlmChat/README.md#releases</a></p><p>或者，我们也可以按照以下步骤，自己编译 Android 和 iOS 应用：</p><p>Android 编译和使用</p><p>    克隆 MNN 源代码：git clone <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/alibaba/MNN.git\">https://github.com/alibaba/MNN.git</a></p><p>    构建库：</p><p>cd project/android</p><p>mkdir build_64</p><p>../build_<a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"http://64.sh\">64.sh</a> &quot;-DMNN_LOW_MEMORY=true -DMNN_CPU_WEIGHT_DEQUANT_GEMM=true -DMNN_BUILD_LLM=true -DMNN_SUPPORT_TRANSFORMER_FUSE=true -DMNN_ARM82=true -DMNN_USE_LOGCAT=true -DMNN_OPENCL=true -DLLM_SUPPORT_VISION=true -DMNN_BUILD_OPENCV=true -DMNN_IMGCODECS=true -DLLM_SUPPORT_AUDIO=true -DMNN_BUILD_AUDIO=true -DMNN_BUILD_DIFFUSION=ON -DMNN_SEP_BUILD=ON&quot;</p><p>    复制到 LLM Android 应用项目：</p><p>mkdir -p ../../../apps/Android/MnnLlmChat/app/src/main/jniLibs/arm64-v8a</p><p>find . -name &quot;*.so&quot; -exec cp {} ../../../apps/Android/MnnLlmChat/app/src/main/jniLibs/arm64-v8a \\;</p><p>    构建 Android 应用项目并安装：</p><p>cd ../../../apps/Android/MnnLlmChat</p><p>./gradlew installDebug</p><p>iOS 应用编译和使用</p><p>    克隆 MNN 源代码：git clone <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/alibaba/MNN.git\">https://github.com/alibaba/MNN.git</a></p><p>    编译 MNN.framework:</p><p>cd MNN/</p><p>sh package_scripts/ios/<a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"http://buildiOS.sh\">buildiOS.sh</a> &quot;-DMNN_ARM82=true -DMNN_LOW_MEMORY=true -DMNN_SUPPORT_TRANSFORMER_FUSE=true -DMNN_BUILD_LLM=true -DMNN_CPU_WEIGHT_DEQUANT_GEMM=true</p><p>-DMNN_METAL=ON</p><p>-DMNN_BUILD_DIFFUSION=ON</p><p>-DMNN_BUILD_OPENCV=ON</p><p>-DMNN_IMGCODECS=ON</p><p>-DMNN_OPENCL=OFF</p><p>-DMNN_SEP_BUILD=OFF</p><p>-DMNN_SUPPORT_TRANSFORMER_FUSE=ON&quot;</p><p>    拷贝 framework 到 iOS 项目中：</p><p>mv MNN-iOS-CPU-GPU/Static/MNN.framework /apps/iOS/MNNLLMChat/MNN.framework</p><p>确保 Link Binary With Libraried 中包含 MNN.framework，和其他三个 Framework:</p><p>Framework</p><p>如果没有包含，可以手动添加 MNN.framework:</p><p>MNN.framework</p><p>    修改 iOS 签名并编译项目</p><p>cd /apps/iOS/MNNLLMChat</p><p>open MNNLLMiOS.xcodeproj</p><p>在 Xcode 项目属性中 Signing &amp; Capabilities &gt; Team 输入自己的账号和 Bundle Identifier:</p><p>签名</p><p>等待 Swift Package 下载完成之后，进行编译使用。</p><p>2.下载模型文件</p><p>手机上安装好MNN Chat应用之后，打开应用，就可以看到它所兼容的模型列表，包括文本、音频、图像等：</p><p>大模型列表</p><p>点击即可下载，想体验一下文本和图片识别，下载DeepSeek-R1-7B-Qwen-MNN和Qwen2-VL-2B-Instruct-MNN这 2 个大模型，等待下载完成。</p><p>3. MNN 模型推理</p><p>先试用一下DeepSeek-R1-7B-Qwen-MNN文本模型，输入提示词：</p><p>同样是一年，为什么阳历固定12个月，而阴历却有闰月？</p><p>DeepSeek文本推理</p><p>DeepSeek R1 开始思考，分析阳历和阴历的计算方法，最终得出结论：</p><p>DeepSeek思考结果</p><p>从手机的推理速率来看，总体还算不错，比通过Termux应用的方式推理效率高多了。</p><p></p><script type=\"module\">const injectHtml = (root, html) => {\n  const iframe = document.createElement(\"iframe\");\n  const htmlContent = `<html><head></head><body>${html}</body></html>`;\n  iframe.style.width = \"100%\";\n  iframe.style.height = \"100%\";\n  iframe.onload = () => {\n    const doc = iframe.contentDocument || iframe.contentWindow?.document;\n    if (!doc) {\n      return;\n    }\n    doc.open();\n    doc.write(htmlContent);\n    doc.close();\n  };\n  root.replaceChildren(iframe);\n}\n  document.querySelectorAll('.playground')?.forEach(el=>{\n    const html = el.getAttribute('data-html');\n    if (html) {\n      injectHtml(el,html);\n    }\n    const indicator = document.createElement(\"div\");\n    indicator.className = \"indicator\";\n    const showCode = document.createElement(\"div\");\n    showCode.className = \"show-code\";\n    showCode.innerText = \"code\";\n    showCode.onclick = () => {\n      el.parentElement.classList.remove(\"preview-only\");\n    };\n    const showPreview = document.createElement(\"div\");\n    showPreview.className = \"show-preview\";\n    showPreview.innerText = \"preview\";\n    showPreview.onclick = () => {\n      el.parentElement.classList.add(\"preview-only\");\n    };\n    indicator.appendChild(showCode);\n    indicator.appendChild(showPreview);\n    el.parentElement.appendChild(indicator);\n    if (window.screen.width < 768) {\n      showPreview.click();\n    }\n  });</script>","id":"Local-llm-on-android-","path":"/posts/Local-llm-on-android-.json"}