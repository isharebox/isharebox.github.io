{"__ud_title":"Nvidia Api LLM model id","__ud_tags":["ai","vibecoding","model"],"__ud_update_time":1771370128511,"__ud_create_time":1770548240812,"__ud_draft":false,"type":"doc","content":[{"type":"heading","attrs":{"level":1,"id":"Nvidia-Api-LLM-model-id"},"content":[{"type":"text","text":"Nvidia Api LLM model id"}]},{"type":"paragraph","content":[{"type":"text","text":"NVIDIA build models , here are the model IDs organized by category: Large Language Models (LLMs)"}]},{"type":"codeBlock","attrs":{"language":null},"content":[{"type":"text","text":"nvidia/nemotron-3-nano-30b-a3b - Open, efficient MoE model with 1M context\ndeepseek-ai/deepseek-v3.2 - 685B reasoning LLM with sparse attention\ndeepseek-ai/deepseek-v3.1 - Hybrid AI model with fast reasoning\nminimaxai/minimax-m2 - 230B MoE model (10B active)\nqwen/qwen3-235b-a22b - Advanced reasoning MoE model\nqwen/qwq-32b - Powerful reasoning model\nmistralai/mistral-nemotron - Built for agentic workflows\nigenius/colosseum_355b_instruct_16k - Multilingual LLM for regulated industries\ntiiuae/falcon3-7b-instruct - Instruction tuned LLM\nigenius/italia_10b_instruct_16k - European languages focused LLM\nmeta/llama-3.1-405b-instruct - Advanced LLM for synthetic data generation\nmeta/llama-3.1-8b-instruct - State-of-the-art model\nmeta/llama3-70b-instruct - Complex conversations model\nmeta/llama3-8b-instruct - Advanced LLM\nmeta/llama-3.2-3b-instruct - Small language model\nmeta/llama-3.2-1b-instruct - Small language model\nqwen/qwen2-7b-instruct - Chinese and English LLM\nthudm/chatglm3-6b - Chinese and English chatbot\ngoogle/gemma-2-27b-it - Text generation model\ngoogle/gemma-2-9b-it - Text generation model\ngoogle/gemma-7b - Text generation model\nrakuten/rakutenai-7b-chat - Advanced LLM"}]},{"type":"paragraph","content":[{"type":"text","text":"Vision-Language Models"}]},{"type":"codeBlock","attrs":{"language":null},"content":[{"type":"text","text":"nvidia/nemotron-parse - Vision-language model for text/metadata extraction\nnvidia/nemotron-nano-12b-v2-vl - Multi-image and video understanding\nnvidia/cosmos-reason2-8b - Physical world understanding\ngoogle/gemma-3n-e4b-it - Edge computing AI with multimodal input\ngoogle/gemma-3n-e2b-it - Edge computing AI with multimodal input\ngoogle/gemma-3-27b-it - Multimodal model for image reasoning\ngoogle/paligemma - Vision language model\nnvidia/nv-clip - Multimodal embeddings model"}]},{"type":"paragraph","content":[{"type":"text","text":"Scientific/Bio Models"}]},{"type":"codeBlock","attrs":{"language":null},"content":[{"type":"text","text":"openfold/openfold3 - Biomolecular foundation model\nopenfold/openfold2 - Protein 3D structure prediction\nmit/boltz-2 - Complex structure prediction\narc/evo2-40b - Biological foundation model\nmeta/esm2-650m - Protein embeddings\nmeta/esmfold - Protein 3D structure prediction\nipd/proteinmpnn - Amino acid sequence prediction\nipd/rfdiffusion - Protein backbone generation\nmit/diffdock - Molecule-protein interaction prediction\nnvidia/maisi - 3D CT Latent Diffusion model\nnvidia/genmol - Molecular generation\nnvidia/molmim-generate - Controlled molecular generation"}]},{"type":"paragraph","content":[{"type":"text","text":"Autonomous Driving"}]},{"type":"codeBlock","attrs":{"language":null},"content":[{"type":"text","text":"nvidia/streampetr - 3D object detection\nnvidia/sparsedrive - End-to-end autonomous driving stack\nnvidia/bevformer - Bird's-eye-view 3D perception"}]},{"type":"paragraph","content":[{"type":"text","text":"3D/Computer Vision"}]},{"type":"codeBlock","attrs":{"language":null},"content":[{"type":"text","text":"microsoft/trellis - 3D asset generation\nnvidia/cosmos-transfer1-7b - Physics-aware video generation\nnvidia/cosmos-predict1-5b - Future frame prediction\nnvidia/nv-dinov2 - Visual foundation model\nnvidia/visual-changenet - Change detection between images"}]},{"type":"paragraph","content":[{"type":"text","text":"Specialized Models"}]},{"type":"codeBlock","attrs":{"language":null},"content":[{"type":"text","text":"nvidia/nemoretriever-ocr - OCR for text extraction\nnvidia/nv-embedcode-7b-v1 - Code retrieval embeddings\nnvidia/llama-3.2-nv-embedqa-1b-v2 - Question-answering retrieval\nnvidia/usdcode - OpenUSD code generation\nnvidia/usdsearch - OpenUSD asset search\nnvidia/usdvalidate - OpenUSD asset validation\nnvidia/audio2face-3d - Audio to facial blendshapes\nnvidia/eyecontact - Gaze angle estimation\nnvidia/studiovoice - Speech enhancement\nnvidia/vista-3d - 3D medical imaging segmentation\nnvidia/ocdrnet - Optical character detection/recognition\nnvidia/corrdiff - Weather field generation\nnvidia/fourcastnet - Atmospheric dynamics prediction\nnvidia/cuopt - Route optimization"}]},{"type":"paragraph","content":[{"type":"text","text":"Other Models"}]},{"type":"codeBlock","attrs":{"language":null},"content":[{"type":"text","text":"baidu/paddleocr - Table extraction and OCR\nbaai/bge-m3 - Text retrieval embeddings\nnvidia/rerank-qa-mistral-4b - Question-answering reranking\ncolabfold/msa-search - Protein sequence alignment\nuniversity-at-buffalo/cached - Chart element detection\n\nModel \tDescription\nminimaxai/minimax-m2.1 \tMinimax latest, strong Chinese capability\nz-ai/glm4.7 \tZhipu GLM4, fast response\nmeta/llama-3.3-70b-instruct \tMeta Llama 3.3 70B\nmeta/llama-3.1-405b-instruct \tMeta Llama 3.1 405B\ndeepseek-ai/deepseek-r1 \tDeepSeek R1 reasoning model\nqwen/qwen2.5-72b-instruct \tAlibaba Qwen 2.5\n"}]},{"type":"paragraph","content":[{"type":"text","text":"deepseek-ai/deepseek-v3.2"}]},{"type":"paragraph","content":[{"type":"text","text":"nvidia/nemotron-3-nano-30b-a3b"}]},{"type":"paragraph","content":[{"type":"text","text":"moonshotai/kimi-k2.5"}]},{"type":"paragraph","content":[{"type":"text","text":"z-ai/glm5"}]},{"type":"paragraph","content":[{"type":"text","text":"qwen/qwen3.5-397b-a17b"}]},{"type":"paragraph"},{"type":"paragraph","content":[{"type":"text","text":"These models are available through NVIDIA's NIM (NVIDIA Inference Microservices) APIs for deployment and inference."}]},{"type":"paragraph","content":[{"type":"text","text":"Full list: "},{"type":"text","marks":[{"type":"link","attrs":{"href":"https://build.nvidia.com/models","target":"_blank","rel":"nofollow","class":null}}],"text":"build.nvidia.com/models"}]},{"type":"paragraph","content":[{"type":"text","marks":[{"type":"link","attrs":{"href":"https://api.chatanywhere.tech","target":"_blank","rel":"noreferer","class":null}}],"text":"https://api.chatanywhere.tech"}]},{"type":"paragraph","content":[{"type":"text","marks":[{"type":"link","attrs":{"href":"https://github.com/chatanywhere/GPT_API_free","target":"_blank","rel":"noopener noreferrer nofollow","class":null}}],"text":"https://github.com/chatanywhere/GPT_API_free"}]},{"type":"paragraph","content":[{"type":"text","marks":[{"type":"link","attrs":{"href":"https://chatanywhere.apifox.cn/doc-5547696","target":"_blank","rel":"noopener noreferrer nofollow","class":null}}],"text":"https://chatanywhere.apifox.cn/doc-5547696"}]},{"type":"orderedList","attrs":{"start":1,"type":null},"content":[{"type":"listItem","content":[{"type":"paragraph","content":[{"type":"text","text":"支持 gpt | deepseek | claude | gemini | grok 等排名靠前的常用大模型。"}]}]},{"type":"listItem","content":[{"type":"paragraph","content":[{"type":"text","text":"免费版支持gpt-5.2, gpt-5.1, gpt-5, gpt-4o，gpt-4.1一天5次；支持deepseek-r1, deepseek-v3, deepseek-v3-2-exp一天30次，支持gpt-4o-mini，gpt-3.5-turbo，gpt-4.1-mini，gpt-4.1-nano, gpt-5-mini，gpt-5-nano一天200次。"}]}]},{"type":"listItem","content":[{"type":"paragraph","content":[{"type":"text","text":"与官方完全一致的接口标准，兼容各种软件/插件。"}]}]},{"type":"listItem","content":[{"type":"paragraph","content":[{"type":"text","text":"支持流式响应。"}]}]},{"type":"listItem","content":[{"type":"paragraph","content":[{"type":"text","text":"国内线路使用动态加速，体验远优于使用代理连接官方。"}]}]},{"type":"listItem","content":[{"type":"paragraph","content":[{"type":"text","text":"无需科学上网，国内环境直接可用。"}]}]},{"type":"listItem","content":[{"type":"paragraph","content":[{"type":"text","text":"个人完全免费使用。"}]}]},{"type":"listItem","content":[{"type":"paragraph","content":[{"type":"text","text":"协议统一使用openai标准协议，其他厂商模型仅需更换模型名称，接入便捷"}]}]}]}]}