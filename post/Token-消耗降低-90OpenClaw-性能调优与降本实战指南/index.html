<!DOCTYPE html> <html lang="zh-CN" class="dark"> <head><meta charset="UTF-8"><link rel="apple-touch-icon-precomposed" sizes="144x144" href="/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="apple-mobile-web-app-title" content="isharebox"><meta name="msapplication-TileColor" content="#1e2030"><meta name="viewport" content="width=device-width,initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover"><meta name="description" content="用 OpenClaw 搭建 AI 助手时，你肯定遇到过这些情况：随便聊几轮就提示达到使用限制，每次提问都要等好几秒甚至十几秒，严重的时候直接卡死。更要命的是，看着 API 账单一路飙升，心里总觉得不值——明明只是想让它回忆一下之前的对话，为什么要塞那么多无关内容进去？"><link rel="icon" href="/favicon.ico"><title>Token 消耗降低 90%：OpenClaw 性能调优与降本实战指南 | isharebox</title><link rel="stylesheet" href="/_astro/_page_.m1rPkfGw.css">
<style>.outlines a[data-anchor-tag=H1]{margin-left:0}.outlines a[data-anchor-tag=H2]{margin-left:12px}.outlines a[data-anchor-tag=H3]{margin-left:24px}.outlines a[data-anchor-tag=H4]{margin-left:36px}.outlines a[data-anchor-tag=H5]{margin-left:48px}.outlines a[data-anchor-tag=H6]{margin-left:60px}
._tabset_selm3_1 ._tab-panel_selm3_1{display:none}._tabset_selm3_1 ._tab-panels_selm3_4{display:flex}._tabset_selm3_1 input[data-tab-name=direct]{display:none}._tabset_selm3_1 input[data-tab-name=direct]:checked~._tab-panels_selm3_4 ._tab-panel_selm3_1[data-tab-name=direct]{display:block}._tabset_selm3_1 input[data-tab-name=direct]:checked~._tab-labels_selm3_13 label[data-tab-name=direct]{border-bottom:2px solid red}._tabset_selm3_1 input[data-tab-name=app]{display:none}._tabset_selm3_1 input[data-tab-name=app]:checked~._tab-panels_selm3_4 ._tab-panel_selm3_1[data-tab-name=app]{display:block}._tabset_selm3_1 input[data-tab-name=app]:checked~._tab-labels_selm3_13 label[data-tab-name=app]{border-bottom:2px solid red}
</style>
<link rel="stylesheet" href="/_astro/_page_.ChTWOvcN.css">
<link rel="stylesheet" href="/_astro/_id_.CdoHgwyN.css"><script type="module" src="/_astro/hoisted.D_gz7ZLf.js"></script></head> <body class="min-h-screen"> <header class="flex justify-between items-center px-4 py-3 border-b" style="border-color: #292e42;"> <a href="/" class="text-lg font-semibold tracking-tight hover:opacity-80 transition-opacity" style="color: #c8d3f5;"> isharebox </a> <div class="flex items-center gap-3">   <div id="auth"></div> </div> </header>  <main> <div class="content"> <div class="w-full flex gap-2 pb-2">   </div> <div class="ud-root read-only flex-1"><h1 level="1" id="Token-消耗降低-90OpenClaw-性能调优与降本实战指南">Token 消耗降低 90%：OpenClaw 性能调优与降本实战指南</h1><p>用 OpenClaw 搭建 AI 助手时，你肯定遇到过这些情况：随便聊几轮就提示达到使用限制，每次提问都要等好几秒甚至十几秒，严重的时候直接卡死。更要命的是，看着 API 账单一路飙升，心里总觉得不值——明明只是想让它回忆一下之前的对话，为什么要塞那么多无关内容进去？</p><h2 level="2" id="问题根源上下文爆炸"><strong>问题根源：上下文爆炸</strong></h2><p></p><img src="https://pic.fmcat.top/picgo/openclaw-qmd/01-infographic-context-explosion.png" alt="上下文爆炸问题可视化"><p>传统的记忆系统会把整个 <a target="_blank" rel="noopener noreferrer nofollow" href="http://MEMORY.md">MEMORY.md</a> 文件直接塞进上下文。但其中 90% 的内容可能和当前问题毫无关系。上下文越长，请求就越慢，成本也越高，AI 还容易被无关信息干扰。</p><p>我遇到过最夸张的情况：一个长期运行的会话，上下文累积到了 <strong>20 万 token</strong>。每次提问要等 1-2 分钟才有回应，最后直接卡死崩溃，API 账单也爆了。</p><p>即使是正常使用，5000-10000 token 的上下文也很常见，每次请求要等 15-30 秒，还经常触发 rate limit。</p><p><strong>不过，OpenClaw 2026.2.2 版本之后，这个问题可以说已经被解决了。</strong></p><hr><h2 level="2" id="解决方案OpenClaw-内置的-QMD-记忆系统"><strong>解决方案：OpenClaw 内置的 QMD 记忆系统</strong></h2><p>OpenClaw 从 2026.2.2 版本开始，内置了 <strong>QMD（Quantum Memory Database）</strong> 记忆后端。这是 Shopify 联合创始人兼 CEO Tobias Lütke (Tobi) 开发的本地语义搜索引擎。</p><h3 level="3" id="QMD-的核心思路"><strong>QMD 的核心思路</strong></h3><p>不要把整个文件塞给 AI，而是先用本地搜索找到最相关的片段（通常只有 2-3 句话），再把这些精准内容传给 AI。</p><p></p><img src="https://pic.fmcat.top/picgo/openclaw-qmd/02-infographic-qmd-vs-traditional.png" alt="QMD vs 传统系统对比"><h3 level="3" id="实际效果有多明显"><strong>实际效果有多明显？</strong></h3><p>根据实际使用数据：</p><p>📊 <strong>Token 削减比例</strong></p><ul><li><p>削减范围：60-97%</p></li><li><p>平均削减：95% 以上</p></li></ul><p>⚡ <strong>响应速度提升</strong></p><ul><li><p>日常场景：5000 token → 响应从 15 秒降到 2 秒</p></li><li><p>长期会话：80000 token → 响应从 45 秒（或超时）降到 3 秒</p></li><li><p>极端情况：20 万 token 从&quot;完全不可用&quot;变成&quot;秒级响应&quot;</p></li></ul><p>💰 <strong>成本降低</strong></p><ul><li><p>API 成本直接降低 90-99%</p></li></ul><p>🎯 <strong>真实案例</strong> 来自 OpenClaw 社区：有个 bot 每次发送整个聊天历史导致 50K+ tokens，造成 context overflow 和崩溃，启用 QMD 后只提取相关内容，问题彻底解决。</p><p><strong>最关键的是：</strong></p><ul><li><p>✅ 完全免费</p></li><li><p>✅ 完全本地运行</p></li><li><p>✅ 数据永远不出你的电脑</p></li><li><p>✅ 不消耗任何 API 配额</p></li></ul><p><strong>相关链接：</strong></p><ul><li><p>QMD GitHub: <a target="_blank" rel="noopener noreferrer nofollow" href="https://link.juejin.cn?target=https%3A%2F%2Fgithub.com%2Ftobi%2Fqmd">github.com/tobi/qmd</a></p></li><li><p>OpenClaw 官网: <a target="_blank" rel="noopener noreferrer nofollow" href="http://openclaw.ai">openclaw.ai</a></p></li></ul><p></p><img src="https://pic.fmcat.top/picgo/openclaw-qmd/04-infographic-performance-improvement.png" alt="性能提升数据可视化"><hr><h2 level="2" id="技术原理为什么-QMD-这么快"><strong>技术原理：为什么 QMD 这么快？</strong></h2><p></p><img src="https://pic.fmcat.top/picgo/openclaw-qmd/03-infographic-qmd-three-layer-search.png" alt="QMD三层混合搜索机制"><p>QMD 采用<strong>三层混合搜索机制</strong>：</p><h3 level="3" id="1-BM25-全文搜索"><strong>1. BM25 全文搜索</strong></h3><p>精准匹配关键词，类似传统搜索引擎</p><h3 level="3" id="2-向量语义搜索"><strong>2. 向量语义搜索</strong></h3><p>理解语义相似度，能找到意思相近但用词不同的内容</p><h3 level="3" id="3-LLM-重排序"><strong>3. LLM 重排序</strong></h3><p>用 AI 对结果进行二次优化，确保最相关的内容排在前面</p><p><strong>性能指标：</strong></p><ul><li><p>混合搜索精准度：93%</p></li><li><p>纯语义搜索精准度：59%</p></li><li><p>混合搜索明显更准确</p></li></ul><p><strong>底层技术：</strong></p><ul><li><p>基于 TypeScript + Bun 开发，使用 node-llama-cpp 运行本地模型</p></li><li><p>12 个文件的索引只需几秒钟</p></li><li><p>所有模型在本地运行（GGUF 格式）：</p><ul><li><p>embeddinggemma-300M-Q8_0（嵌入）</p></li><li><p>qwen3-reranker-0.6b-q8_0（重排序）</p></li><li><p>qmd-query-expansion-1.7B-q4_k_m（查询扩展）</p></li></ul></li><li><p>完全离线，首次下载模型后不需要联网</p></li></ul><hr><h2 level="2" id="如何在-OpenClaw-中启用-QMD"><strong>如何在 OpenClaw 中启用 QMD</strong></h2><p></p><img src="https://pic.fmcat.top/picgo/openclaw-qmd/05-infographic-installation-flow.png" alt="安装配置流程图"><h3 level="3" id="前提条件"><strong>前提条件</strong></h3><p>⚠️ <strong>OpenClaw 版本需要 ≥ 2026.2.2</strong></p><p>检查你的版本：</p><div class="llt-code readonly"><div class="language">auto</div><div class="wrapper"><pre><code></code></pre></div></div><div class="llt-code readonly"><div class="language">bash</div><div class="wrapper"><pre><code class="language-bash">openclaw --version
</code></pre></div></div><p>如果版本低于 2026.2.2，需要先更新到最新版本。</p><hr><h3 level="3" id="第一步安装-QMD-CLI"><strong>第一步：安装 QMD CLI</strong></h3><h4 level="4" id="11-安装-QMD"><strong>1.1 安装 QMD</strong></h4><p>所有平台统一使用以下命令：</p><div class="llt-code readonly"><div class="language">auto</div><div class="wrapper"><pre><code></code></pre></div></div><div class="llt-code readonly"><div class="language">bash</div><div class="wrapper"><pre><code class="language-bash">npm i -g bun
bun install -g github:tobi/qmd
</code></pre></div></div><p>首次运行会自动下载模型 embeddinggemma-300M-Q8_0.gguf（约 330MB）</p><hr><h4 level="4" id="12-安装支持扩展的-SQLite"><strong>1.2 安装支持扩展的 SQLite</strong></h4><p>QMD 需要支持 vector 扩展的 SQLite。不同操作系统的安装方法：</p><p><strong>macOS 用户：</strong></p><p>使用 Homebrew 安装：</p><div class="llt-code readonly"><div class="language">auto</div><div class="wrapper"><pre><code></code></pre></div></div><div class="llt-code readonly"><div class="language">bash</div><div class="wrapper"><pre><code class="language-bash">brew install sqlite
</code></pre></div></div><p>验证安装：</p><div class="llt-code readonly"><div class="language">auto</div><div class="wrapper"><pre><code></code></pre></div></div><div class="llt-code readonly"><div class="language">bash</div><div class="wrapper"><pre><code class="language-bash">sqlite3 --version
</code></pre></div></div><p><strong>Linux 用户：</strong></p><p>根据发行版选择对应命令：</p><div class="llt-code readonly"><div class="language">auto</div><div class="wrapper"><pre><code></code></pre></div></div><div class="llt-code readonly"><div class="language">bash</div><div class="wrapper"><pre><code class="language-bash"><span class="hljs-comment" class="hljs-comment"># Debian/Ubuntu</span>
<span class="hljs-built_in" class="hljs-built_in">sudo</span> apt update
<span class="hljs-built_in" class="hljs-built_in">sudo</span> apt install sqlite3 libsqlite3-dev

<span class="hljs-comment" class="hljs-comment"># Fedora/RHEL/CentOS</span>
<span class="hljs-built_in" class="hljs-built_in">sudo</span> dnf install sqlite sqlite-devel

<span class="hljs-comment" class="hljs-comment"># Arch Linux</span>
<span class="hljs-built_in" class="hljs-built_in">sudo</span> pacman -S sqlite
</code></pre></div></div><p>验证安装：</p><div class="llt-code readonly"><div class="language">auto</div><div class="wrapper"><pre><code></code></pre></div></div><div class="llt-code readonly"><div class="language">bash</div><div class="wrapper"><pre><code class="language-bash">sqlite3 --version
</code></pre></div></div><p><strong>Windows 用户：</strong></p><p>有两种安装方式：</p><p><strong>方式一：使用 Chocolatey（推荐）</strong></p><p>如果已安装 Chocolatey，执行：</p><div class="llt-code readonly"><div class="language">auto</div><div class="wrapper"><pre><code></code></pre></div></div><div class="llt-code readonly"><div class="language">text</div><div class="wrapper"><pre><code class="language-powershell">choco install sqlite
</code></pre></div></div><p><strong>方式二：手动安装</strong></p><ol><li><p>访问 SQLite 官网下载页面：<a target="_blank" rel="noopener noreferrer nofollow" href="https://link.juejin.cn?target=https%3A%2F%2Fwww.sqlite.org%2Fdownload.html">www.sqlite.org/download.ht…</a></p></li><li><p>下载 &quot;Precompiled Binaries for Windows&quot; 中的：</p><ul><li><p><code>sqlite-tools-win-x64-*.zip</code>（包含 sqlite3.exe）</p></li></ul></li><li><p>解压到任意目录（例如 <code>C:\sqlite</code>）</p></li><li><p>将该目录添加到系统 PATH 环境变量：</p><ul><li><p>右键&quot;此电脑&quot; → &quot;属性&quot; → &quot;高级系统设置&quot;</p></li><li><p>&quot;环境变量&quot; → 编辑&quot;Path&quot;变量</p></li><li><p>添加解压路径（例如 <code>C:\sqlite</code>）</p></li></ul></li><li><p>重启终端，验证安装： </p><div class="llt-code readonly"><div class="language">auto</div><div class="wrapper"><pre><code></code></pre></div></div></li></ol><ol><li><p></p></li></ol><div class="llt-code readonly"><div class="language">text</div><div class="wrapper"><pre><code class="language-powershell">sqlite3 --version
</code></pre></div></div><hr><h4 level="4" id="13-验证-QMD-安装"><strong>1.3 验证 QMD 安装</strong></h4><p>安装完成后，验证 QMD 是否正常工作：</p><div class="llt-code readonly"><div class="language">auto</div><div class="wrapper"><pre><code></code></pre></div></div><div class="llt-code readonly"><div class="language">bash</div><div class="wrapper"><pre><code class="language-bash">qmd --version
</code></pre></div></div><p>如果显示版本号，说明安装成功</p><hr><h3 level="3" id="第二步配置-OpenClaw-使用-QMD"><strong>第二步：配置 OpenClaw 使用 QMD</strong></h3><h4 level="4" id="21-找到配置文件"><strong>2.1 找到配置文件</strong></h4><p>根据你使用的版本和操作系统，配置文件位置：</p><p><strong>OpenClaw 用户：</strong></p><ul><li><p>macOS/Linux：<code>~/.openclaw/openclaw.json</code></p></li><li><p>Windows：<code>C:\Users\你的用户名\.openclaw\openclaw.json</code></p></li></ul><hr><h4 level="4" id="22-修改配置"><strong>2.2 修改配置</strong></h4><p>在配置文件中添加或修改以下内容：</p><div class="llt-code readonly"><div class="language">auto</div><div class="wrapper"><pre><code></code></pre></div></div><div class="llt-code readonly"><div class="language">json</div><div class="wrapper"><pre><code class="language-json"><span class="hljs-punctuation" class="hljs-punctuation">{</span>
  <span class="hljs-attr" class="hljs-attr">&quot;memory&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
    <span class="hljs-attr" class="hljs-attr">&quot;backend&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-string" class="hljs-string">&quot;qmd&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">,</span>
    <span class="hljs-attr" class="hljs-attr">&quot;qmd&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
      <span class="hljs-attr" class="hljs-attr">&quot;limits&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
        <span class="hljs-attr" class="hljs-attr">&quot;timeoutMs&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-number" class="hljs-number">8000</span>
      <span class="hljs-punctuation" class="hljs-punctuation">}</span>
    <span class="hljs-punctuation" class="hljs-punctuation">}</span>
  <span class="hljs-punctuation" class="hljs-punctuation">}</span>
<span class="hljs-punctuation" class="hljs-punctuation">}</span>
</code></pre></div></div><p><strong>配置说明：</strong></p><ul><li><p><code>backend: &quot;qmd&quot;</code> - 切换到 QMD 记忆后端</p></li><li><p><code>timeoutMs: 8000</code> - 设置超时时间为 8 秒（默认 4 秒可能不够）</p></li></ul><p>💡 <strong>提示：</strong> 所有操作系统的配置内容完全相同，只是文件路径不同</p><hr><h3 level="3" id="第三步重启-OpenClaw"><strong>第三步：重启 OpenClaw</strong></h3><p>所有操作系统使用相同命令：</p><div class="llt-code readonly"><div class="language">auto</div><div class="wrapper"><pre><code></code></pre></div></div><div class="llt-code readonly"><div class="language">bash</div><div class="wrapper"><pre><code class="language-bash"><span class="hljs-comment" class="hljs-comment"># 重启 OpenClaw Gateway 服务</span>
openclaw gateway restart

<span class="hljs-comment" class="hljs-comment"># 或者在聊天中发送命令（仅限 owner）</span>
/restart
</code></pre></div></div><p><strong>Windows 用户提示：</strong></p><ul><li><p>在 PowerShell 或 CMD 中执行上述命令</p></li><li><p>如果命令无法识别，确认 OpenClaw 已正确添加到系统 PATH</p></li></ul><p><strong>重启后：</strong></p><ul><li><p>OpenClaw 会自动使用 QMD 进行记忆检索</p></li><li><p>如果 QMD 出现问题，会自动回退到内置的 SQLite 记忆系统</p></li><li><p>不影响正常使用</p></li></ul><p><strong>验证 QMD 是否正常工作：</strong></p><p>查看 OpenClaw 日志，确认 QMD 后端已启用：</p><div class="llt-code readonly"><div class="language">auto</div><div class="wrapper"><pre><code></code></pre></div></div><div class="llt-code readonly"><div class="language">bash</div><div class="wrapper"><pre><code class="language-bash">openclaw logs --follow
</code></pre></div></div><p>如果看到类似 <code>Using QMD memory backend</code> 的日志，说明配置成功</p><hr><h2 level="2" id="实测对比效果有多惊人"><strong>实测对比：效果有多惊人？</strong></h2><p>我在启用 QMD 前后做了对比测试，结果让人惊喜。</p><p></p><img src="https://pic.fmcat.top/picgo/openclaw-qmd/06-infographic-test-scenarios-comparison.png" alt="实测场景对比总览"><h3 level="3" id="场景一长期会话记忆查询"><strong>场景一：长期会话记忆查询</strong></h3><p><strong>测试问题：</strong> &quot;我们三个月前讨论的那个项目，最后用的什么方案？&quot;</p><p>对比项启用前启用后改善幅度上下文大小8 万+ tokens削减 95%+-响应时间45 秒（超时失败）2 秒<strong>快 20+ 倍</strong>API 成本$2.4$0.01<strong>降低 200+ 倍</strong>成功率失败成功✅</p><p><strong>结论：</strong> 速度快了 20+ 倍，成本降低 200+ 倍，而且不会失败。</p><hr><h3 level="3" id="场景二跨文件知识检索"><strong>场景二：跨文件知识检索</strong></h3><p><strong>测试问题：</strong> &quot;我们之前所有项目用过哪些技术栈？&quot;</p><p>对比项启用前启用后改善幅度上下文大小15000+ tokens削减 90%+-响应时间25-30 秒3 秒<strong>快 10 倍</strong>稳定性容易触发 rate limit 卡死从不卡死✅</p><p><strong>结论：</strong> 速度提升 10 倍，再也没卡死过。</p><hr><h3 level="3" id="场景三日常对话"><strong>场景三：日常对话</strong></h3><p><strong>测试问题：</strong> &quot;帮我写个函数&quot;</p><p>对比项启用前启用后改善幅度上下文大小5000+ tokens削减 95%+-响应时间8-10 秒1 秒<strong>快 8-10 倍</strong>体验感觉慢秒级响应💯</p><p><strong>结论：</strong> 日常使用体验天差地别。</p><hr><h2 level="2" id="技术深度为什么上下文变小速度就快那么多"><strong>技术深度：为什么上下文变小，速度就快那么多？</strong></h2><p></p><img src="https://pic.fmcat.top/picgo/openclaw-qmd/07-infographic-token-performance-relationship.png" alt="Token数量与性能关系"><p>大模型的推理时间和输入 token 数量基本成<strong>正比关系</strong>：</p><p>上下文大小平均响应时间成本水平稳定性200 tokens0.5-1 秒💰✅2000 tokens5-8 秒💰💰💰✅10000 tokens25-40 秒💰💰💰💰💰⚠️50000 tokens1-2 分钟💰💰💰💰💰💰💰💰❌ 容易超时100000+ tokens2-5 分钟💰💰💰💰💰💰💰💰💰💰❌ 基本失败</p><p><strong>我的极端案例：</strong></p><p>那个 20 万 token 的会话，单次请求成本高达 <strong>$6-8</strong>，而且基本上都是超时失败，钱白花了。</p><p><strong>启用 QMD 后：</strong></p><p>无论历史记录有多长，每次只提取最相关的几句话（通常削减 95% 以上）。</p><p>✅ 响应快了 5-50 倍 ✅ 成本降低 90-99% ✅ 精准度反而更高（因为噪音少了） ✅ <strong>再也不会因为上下文太长而卡死或超时</strong></p><hr><h2 level="2" id="全面对比启用-QMD-前后"><strong>全面对比：启用 QMD 前后</strong></h2><p></p><img src="https://pic.fmcat.top/picgo/openclaw-qmd/08-infographic-qmd-comparison.png" alt="启用QMD前后全面对比"><p>未启用 QMD启用 QMD<strong>响应速度</strong>5-120 秒（长会话直接超时）1-3 秒（快 5-50 倍）<strong>Token 削减</strong>完整上下文（5K-200K tokens）削减 60-97%（平均 95%+）<strong>单次 API 成本</strong>$0.05-8（长会话）降低 90-99%<strong>精准度</strong>容易被干扰93% 准确率<strong>稳定性</strong>长会话必卡死从不卡死<strong>隐私</strong>数据本地完全本地<strong>成本</strong>持续消耗 API完全免费</p><hr><h2 level="2" id="什么情况下特别推荐"><strong>什么情况下特别推荐？</strong></h2><p>如果你符合以下任一情况，强烈建议启用 QMD：</p><h3 level="3" id="必须启用的情况"><strong>必须启用的情况</strong></h3><ul><li><p>🔴 会话历史超过 1 万 token（基本上运行一周就会超过）</p></li><li><p>🔴 经常被慢速响应或卡死困扰（特别是长期会话）</p></li><li><p>🔴 单次请求成本超过 $1</p></li></ul><h3 level="3" id="高度推荐的情况"><strong>高度推荐的情况</strong></h3><ul><li><p>🟡 每月 API 账单让你心疼</p></li><li><p>🟡 需要跨多个文档和对话查找信息</p></li><li><p>🟡 OpenClaw 主要用于飞书、钉钉等企业场景（24/7 运行）</p></li><li><p>🟡 想要更精准的 AI 回答</p></li></ul><h3 level="3" id="结论"><strong>结论</strong></h3><p>QMD 基本上就是零成本的生产力提升。</p><p>⚠️ <strong>特别提醒：</strong> 长期运行的 Agent，不启用 QMD 几乎不可用。</p><hr><h2 level="2" id="常见问题"><strong>常见问题</strong></h2><p></p><img src="https://pic.fmcat.top/picgo/openclaw-qmd/09-infographic-faq.png" alt="QMD常见问题解答"><h3 level="3" id="QQMD-会影响回答质量吗"><strong>Q：QMD 会影响回答质量吗？</strong></h3><p>A：不会，反而会更好。因为 QMD 过滤掉了 90% 的无关信息，AI 更容易专注于真正相关的内容，精准度达到 93%。</p><h3 level="3" id="QQMD-占用多少存储空间"><strong>Q：QMD 占用多少存储空间？</strong></h3><p>A：</p><ul><li><p>QMD 模型文件：约 2GB（一次性下载，包含 3 个模型）</p><ul><li><p>embeddinggemma-300M-Q8_0: ~330MB（嵌入模型）</p></li><li><p>qwen3-reranker-0.6b-q8_0: ~640MB（重排序模型）</p></li><li><p>qmd-query-expansion-1.7B-q4_k_m: ~1.1GB（查询扩展模型）</p></li></ul></li><li><p>索引文件：取决于你的文档数量，通常很小</p></li></ul><h3 level="3" id="QQMD-需要联网吗"><strong>Q：QMD 需要联网吗？</strong></h3><p>A：不需要。首次下载模型后，完全离线运行。</p><h3 level="3" id="QQMD-支持中文吗"><strong>Q：QMD 支持中文吗？</strong></h3><p>A：完全支持。使用的是多语言重排序模型 qwen3-reranker-0.6b，支持 100+ 种语言。</p><h3 level="3" id="Q如果-QMD-出问题了怎么办"><strong>Q：如果 QMD 出问题了怎么办？</strong></h3><p>A：OpenClaw 会自动回退到内置的 SQLite 记忆系统，不会影响正常使用。你可以查看日志：</p><div class="llt-code readonly"><div class="language">auto</div><div class="wrapper"><pre><code></code></pre></div></div><div class="llt-code readonly"><div class="language">bash</div><div class="wrapper"><pre><code class="language-bash">openclaw logs --follow
</code></pre></div></div><h3 level="3" id="Q可以卸载-QMD-吗"><strong>Q：可以卸载 QMD 吗？</strong></h3><p>A：可以。删除配置文件中的 QMD 设置，重启 OpenClaw 即可：</p><div class="llt-code readonly"><div class="language">auto</div><div class="wrapper"><pre><code></code></pre></div></div><div class="llt-code readonly"><div class="language">json</div><div class="wrapper"><pre><code class="language-json"><span class="hljs-punctuation" class="hljs-punctuation">{</span>
  <span class="hljs-attr" class="hljs-attr">&quot;memory&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
    <span class="hljs-attr" class="hljs-attr">&quot;backend&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-string" class="hljs-string">&quot;sqlite&quot;</span>  <span class="hljs-comment" class="hljs-comment">// 改回默认</span>
  <span class="hljs-punctuation" class="hljs-punctuation">}</span>
<span class="hljs-punctuation" class="hljs-punctuation">}</span>
</code></pre></div></div><hr><h2 level="2" id="总结"><strong>总结</strong></h2><p>QMD 是 OpenClaw 2026.2.2 版本引入的革命性功能，通过智能的本地语义搜索，将上下文 token 削减 95% 以上，带来：</p><p>✅ <strong>5-50 倍的速度提升</strong> ✅ <strong>90-99% 的成本降低</strong> ✅ <strong>93% 的精准度</strong> ✅ <strong>完全本地运行，零 API 成本</strong> ✅ <strong>彻底解决长会话卡死问题</strong></p><p>如果你在用 OpenClaw，<strong>QMD 是必装的</strong>。</p><script type="module">const injectHtml = (root, html) => {
  const iframe = document.createElement("iframe");
  const htmlContent = `<html><head></head><body>${html}</body></html>`;
  iframe.style.width = "100%";
  iframe.style.height = "100%";
  iframe.onload = () => {
    const doc = iframe.contentDocument || iframe.contentWindow?.document;
    if (!doc) {
      return;
    }
    doc.open();
    doc.write(htmlContent);
    doc.close();
  };
  root.replaceChildren(iframe);
}
  document.querySelectorAll('.playground')?.forEach(el=>{
    const html = el.getAttribute('data-html');
    if (html) {
      injectHtml(el,html);
    }
    const indicator = document.createElement("div");
    indicator.className = "indicator";
    const showCode = document.createElement("div");
    showCode.className = "show-code";
    showCode.innerText = "code";
    showCode.onclick = () => {
      el.parentElement.classList.remove("preview-only");
    };
    const showPreview = document.createElement("div");
    showPreview.className = "show-preview";
    showPreview.innerText = "preview";
    showPreview.onclick = () => {
      el.parentElement.classList.add("preview-only");
    };
    indicator.appendChild(showCode);
    indicator.appendChild(showPreview);
    el.parentElement.appendChild(indicator);
    if (window.screen.width < 768) {
      showPreview.click();
    }
  });</script></div> <div data-page-id="Token-消耗降低-90OpenClaw-性能调优与降本实战指南" class="navigator flex justify-between items-center mt-4 py-4"> <a href="/post/同一电脑配置多github帐号" class="flex items-center gap-1 text-blue cursor-pointer flex-[45%]"> <div class="i-ri:arrow-left-double-line w-5 h-5 flex-shrink-0"></div> <div class="text-start">同一电脑配置多github帐号</div> </a> <a href="/post/用-Python-5-分钟搭一个多模型-AI-API-网关附完整代码" class="flex items-center justify-end gap-1 text-blue cursor-pointer flex-[45%]"> <div class="text-end">用 Python 5 分钟搭一个多模型 AI API 网关（附完整代码）</div> <div class="i-ri:arrow-right-double-line w-5 h-5 flex-shrink-0"></div> </a> </div> </div> <div class="outline-wrapper"></div> </main>  <footer class="site-footer" data-astro-cid-sz7xmlte> <!-- 导航链接 --> <nav class="footer-nav" data-astro-cid-sz7xmlte>  <a href="/" class="footer-link" data-astro-cid-sz7xmlte> Home </a> <span class="nav-dot" data-astro-cid-sz7xmlte>·</span> <a href="/tag/projects" class="footer-link" data-astro-cid-sz7xmlte> Projects </a> <span class="nav-dot" data-astro-cid-sz7xmlte>·</span> <a href="/tools" class="footer-link" data-astro-cid-sz7xmlte> Notes </a> <span class="nav-dot" data-astro-cid-sz7xmlte>·</span> <a href="https://web.chatboxai.app/" class="footer-link" target="_blank" rel="noopener noreferrer" data-astro-cid-sz7xmlte> Chatbox </a> <span class="nav-dot" data-astro-cid-sz7xmlte>·</span> <a href="/about" class="footer-link" data-astro-cid-sz7xmlte> About </a>  </nav> <!-- 分割线 --> <div class="footer-divider" data-astro-cid-sz7xmlte></div> <!-- 版权信息 --> <div class="footer-copyright" data-astro-cid-sz7xmlte> <a href="https://isharebox.github.io" data-astro-cid-sz7xmlte>©  isharebox  ·  since 2026  </a> </div> </footer>  <!-- ★ 添加回到顶部按钮组件 --> <button id="back-to-top" class="back-to-top" aria-label="Back to top" data-astro-cid-wlspcwf4> <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" data-astro-cid-wlspcwf4> <path d="M18 15l-6-6-6 6" data-astro-cid-wlspcwf4></path> </svg> </button>   </body></html>