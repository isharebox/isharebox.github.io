<!DOCTYPE html> <html lang="zh-CN" class="dark"> <head><meta charset="UTF-8"><link rel="apple-touch-icon-precomposed" sizes="144x144" href="/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="apple-mobile-web-app-title" content="isharebox"><meta name="msapplication-TileColor" content="#1e2030"><meta name="viewport" content="width=device-width,initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover"><meta name="description" content="Here’s a practical, step‑by‑step configuration guide for nanobot on GitHub."><link rel="icon" href="/favicon.ico"><title>step‑by‑step configuration guide for nanobot | isharebox</title><link rel="stylesheet" href="/_astro/_page_.DsyHAQ0S.css">
<style>._tabset_selm3_1 ._tab-panel_selm3_1{display:none}._tabset_selm3_1 ._tab-panels_selm3_4{display:flex}._tabset_selm3_1 input[data-tab-name=direct]{display:none}._tabset_selm3_1 input[data-tab-name=direct]:checked~._tab-panels_selm3_4 ._tab-panel_selm3_1[data-tab-name=direct]{display:block}._tabset_selm3_1 input[data-tab-name=direct]:checked~._tab-labels_selm3_13 label[data-tab-name=direct]{border-bottom:2px solid red}._tabset_selm3_1 input[data-tab-name=app]{display:none}._tabset_selm3_1 input[data-tab-name=app]:checked~._tab-panels_selm3_4 ._tab-panel_selm3_1[data-tab-name=app]{display:block}._tabset_selm3_1 input[data-tab-name=app]:checked~._tab-labels_selm3_13 label[data-tab-name=app]{border-bottom:2px solid red}
.outlines a[data-anchor-tag=H1]{margin-left:0}.outlines a[data-anchor-tag=H2]{margin-left:12px}.outlines a[data-anchor-tag=H3]{margin-left:24px}.outlines a[data-anchor-tag=H4]{margin-left:36px}.outlines a[data-anchor-tag=H5]{margin-left:48px}.outlines a[data-anchor-tag=H6]{margin-left:60px}
</style>
<link rel="stylesheet" href="/_astro/_page_.ypUYv9mY.css">
<link rel="stylesheet" href="/_astro/_id_.CdoHgwyN.css"><script type="module" src="/_astro/hoisted._hzYIUG3.js"></script></head> <body class="min-h-screen"> <header class="flex justify-between items-center px-4 py-3 border-b" style="border-color: #292e42;"> <a href="/" class="text-lg font-semibold tracking-tight hover:opacity-80 transition-opacity" style="color: #c8d3f5;"> isharebox </a> <div class="flex items-center gap-3">   <div id="auth"></div> </div> </header>  <main> <div class="content"> <div class="w-full flex gap-2 pb-2">  <a href="/tag/nanobot" class="rounded hover:bg-gray-200 dark:hover:bg-modal px-3 py-1 cursor-pointer">
#nanobot </a> </div> <div class="ud-root read-only flex-1"><h1 level="1" id="stepbystep-configuration-guide-for-nanobot">step‑by‑step configuration guide for <strong>nanobot</strong></h1><p>Here’s a practical, step‑by‑step configuration guide for <strong>nanobot on GitHub</strong>.</p><p>香港大学数据科学实验室（HKUDS）的一个项目，他们把 OpenClaw 的核心能力压缩到了 3663 行 Python 代码里，砍掉了 99% 的体量，但保留了 agent loop、tool 调用、多渠道接入、定时任务、持久化记忆这些关键模块。2 月 2 号上线，两周拿下 19000+ stars。</p><img src="https://pica.zhimg.com/80/v2-3f1c28c4eb82b7ca4dc0d7c775747c71_720w.webp?source=2c26e567"><h2 level="2" id="项目定位与背景"><strong>项目定位与背景</strong></h2><p>nanobot 解决的是给个人或小团队提供一个自托管的 AI 助手，能接&nbsp;<a target="_blank" rel="noopener noreferrer nofollow" class="RichContent-EntityWord css-b7erz1" href="https://zhida.zhihu.com/search?content_id=769614043&amp;content_type=Answer&amp;match_order=1&amp;q=Telegram&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NzEzNjk5MzcsInEiOiJUZWxlZ3JhbSIsInpoaWRhX3NvdXJjZSI6ImVudGl0eSIsImNvbnRlbnRfaWQiOjc2OTYxNDA0MywiY29udGVudF90eXBlIjoiQW5zd2VyIiwibWF0Y2hfb3JkZXIiOjEsInpkX3Rva2VuIjpudWxsfQ.Yw9fMwwnJA7XTlDwktOKcGpGqnGs_s8nYFI67rOs8os&amp;zhida_source=entity">Telegram</a>、<a target="_blank" rel="noopener noreferrer nofollow" class="RichContent-EntityWord css-b7erz1" href="https://zhida.zhihu.com/search?content_id=769614043&amp;content_type=Answer&amp;match_order=1&amp;q=Discord&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NzEzNjk5MzcsInEiOiJEaXNjb3JkIiwiemhpZGFfc291cmNlIjoiZW50aXR5IiwiY29udGVudF9pZCI6NzY5NjE0MDQzLCJjb250ZW50X3R5cGUiOiJBbnN3ZXIiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.zm-y8B_NUccIOweENgwR-Ti_Ke_GGdf5AVAE8Mfh4Xw&amp;zhida_source=entity">Discord</a>、<a target="_blank" rel="noopener noreferrer nofollow" class="RichContent-EntityWord css-b7erz1" href="https://zhida.zhihu.com/search?content_id=769614043&amp;content_type=Answer&amp;match_order=1&amp;q=WhatsApp&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NzEzNjk5MzcsInEiOiJXaGF0c0FwcCIsInpoaWRhX3NvdXJjZSI6ImVudGl0eSIsImNvbnRlbnRfaWQiOjc2OTYxNDA0MywiY29udGVudF90eXBlIjoiQW5zd2VyIiwibWF0Y2hfb3JkZXIiOjEsInpkX3Rva2VuIjpudWxsfQ.7TkdWEjlOjZy3LIXrmlWAwUHqm_0Q6QECYrohugq-kA&amp;zhida_source=entity">WhatsApp</a>、<a target="_blank" rel="noopener noreferrer nofollow" class="RichContent-EntityWord css-b7erz1" href="https://zhida.zhihu.com/search?content_id=769614043&amp;content_type=Answer&amp;match_order=1&amp;q=%E9%A3%9E%E4%B9%A6&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NzEzNjk5MzcsInEiOiLpo57kuaYiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjo3Njk2MTQwNDMsImNvbnRlbnRfdHlwZSI6IkFuc3dlciIsIm1hdGNoX29yZGVyIjoxLCJ6ZF90b2tlbiI6bnVsbH0.DhUCmaJ1-Tz_VEcGJOi-zrKEmOsCaOJ9FWTKPiB5S-o&amp;zhida_source=entity">飞书</a>、<a target="_blank" rel="noopener noreferrer nofollow" class="RichContent-EntityWord css-b7erz1" href="https://zhida.zhihu.com/search?content_id=769614043&amp;content_type=Answer&amp;match_order=1&amp;q=%E9%92%89%E9%92%89&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NzEzNjk5MzcsInEiOiLpkonpkokiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjo3Njk2MTQwNDMsImNvbnRlbnRfdHlwZSI6IkFuc3dlciIsIm1hdGNoX29yZGVyIjoxLCJ6ZF90b2tlbiI6bnVsbH0.Wca3qx-kmhL_69v71JETdkGJhoc4nHdoXmOKH-fW1pQ&amp;zhida_source=entity">钉钉</a>、<a target="_blank" rel="noopener noreferrer nofollow" class="RichContent-EntityWord css-b7erz1" href="https://zhida.zhihu.com/search?content_id=769614043&amp;content_type=Answer&amp;match_order=1&amp;q=Slack&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NzEzNjk5MzcsInEiOiJTbGFjayIsInpoaWRhX3NvdXJjZSI6ImVudGl0eSIsImNvbnRlbnRfaWQiOjc2OTYxNDA0MywiY29udGVudF90eXBlIjoiQW5zd2VyIiwibWF0Y2hfb3JkZXIiOjEsInpkX3Rva2VuIjpudWxsfQ.hgWvIE7CgnG0vcldlw6lRPtJW7aRx_AQK1QAwXOWr_g&amp;zhida_source=entity">Slack</a>、邮件、QQ 这些渠道，背后跑一个具备工具调用能力的 agent。</p><p>与 OpenClaw 比较：</p><p><strong>维度OpenClaw / Clawdbotnanobot</strong>代码量43 万行3663 行部署复杂度较高，依赖多pip install 即可渠道覆盖全平台9 个渠道，覆盖主流 IM二次开发门槛代码量大，模块耦合源码可读，改造成本低成熟度生产级Alpha 阶段，迭代快</p><p>如果你需要一个经过验证的生产级产品，OpenClaw 更适合你。如果你要一个能 fork 下来快速定制的 agent 底座，或者做 agent 相关的学术研究，nanobot 更值得你去学习。</p><h2 level="2" id="核心功能"><strong>核心功能</strong></h2><ul><li><p><strong>Agent Loop 与工具调用</strong>：核心循环在&nbsp;<code>agent/loop.py</code>，LLM 调用和工具执行交替进行。内置 shell 执行、文件读写、目录浏览等工具，也支持通过&nbsp;<a target="_blank" rel="noopener noreferrer nofollow" class="RichContent-EntityWord css-b7erz1" href="https://zhida.zhihu.com/search?content_id=769614043&amp;content_type=Answer&amp;match_order=1&amp;q=MCP+%E5%8D%8F%E8%AE%AE&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NzEzNjk5MzcsInEiOiJNQ1Ag5Y2P6K6uIiwiemhpZGFfc291cmNlIjoiZW50aXR5IiwiY29udGVudF9pZCI6NzY5NjE0MDQzLCJjb250ZW50X3R5cGUiOiJBbnN3ZXIiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.CHob4l1WsdoFofdvoj1WGU1uE2s2tgFJFXjdAwMJrx8&amp;zhida_source=entity">MCP 协议</a>接入外部工具服务器。</p></li><li><p><strong>多 LLM Provider 支持</strong>：通过 LiteLLM 统一路由，支持&nbsp;<a target="_blank" rel="noopener noreferrer nofollow" class="RichContent-EntityWord css-b7erz1" href="https://zhida.zhihu.com/search?content_id=769614043&amp;content_type=Answer&amp;match_order=1&amp;q=OpenRouter&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NzEzNjk5MzcsInEiOiJPcGVuUm91dGVyIiwiemhpZGFfc291cmNlIjoiZW50aXR5IiwiY29udGVudF9pZCI6NzY5NjE0MDQzLCJjb250ZW50X3R5cGUiOiJBbnN3ZXIiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.f0wwhDqm2Wh1TqmCVtowymKr-7u4pEMkz9d2TVwLu3I&amp;zhida_source=entity">OpenRouter</a>、Anthropic、OpenAI、DeepSeek、Groq、Gemini、Moonshot、智谱、MiniMax、通义千问，以及 vLLM 本地推理。新增 provider 只需改两个文件。</p></li><li><p><strong>9 渠道接入</strong>：Telegram、Discord、WhatsApp、飞书、钉钉、Slack、Email、QQ、Mochat。<code>nanobot gateway</code>&nbsp;一条命令启动网关，消息自动路由到 agent。</p></li><li><p><strong>定时任务</strong>：<code>nanobot cron add</code>&nbsp;支持 cron 表达式和固定间隔，用于定期执行 agent 指令。</p></li><li><p><strong>持久化记忆</strong>：<code>agent/memory.py</code>&nbsp;实现跨会话记忆，agent 能记住之前的交互内容。</p></li><li><p><strong>MCP 协议兼容</strong>：配置格式和 Claude Desktop / Cursor 完全兼容，直接把 MCP Server 的 README 配置复制过来就能用。</p></li></ul><img src="https://picx.zhimg.com/80/v2-cfc1d0fedb06cc104d981716adcde01d_720w.webp?source=2c26e567"><p>项目结构</p><h2 level="2" id="部署与安装"><strong>部署与安装</strong></h2><h3 level="3" id="前置环境"><strong>前置环境</strong></h3><ul><li><p>Python ≥ 3.11</p></li><li><p>Node.js ≥ 18（仅 WhatsApp 渠道需要）</p></li><li><p>至少一个 LLM API Key（推荐 OpenRouter，一个 key 可以调所有模型）</p></li></ul><h3 level="3" id="方式一pip-安装"><strong>方式一：pip 安装</strong></h3><div class="llt-code readonly"><div class="language">bash</div><div class="wrapper"><pre><code class="language-bash">pip install nanobot-ai
​
<span class="hljs-comment" class="hljs-comment"># 初始化配置目录</span>
nanobot onboard</code></pre></div></div><h3 level="3" id="方式二源码安装"><strong>方式二：源码安装</strong></h3><div class="llt-code readonly"><div class="language">bash</div><div class="wrapper"><pre><code class="language-bash">git <span class="hljs-built_in" class="hljs-built_in">clone</span> https://github.com/HKUDS/nanobot.git
<span class="hljs-built_in" class="hljs-built_in">cd</span> nanobot
pip install -e .
nanobot onboard</code></pre></div></div><h3 level="3" id="方式三Docker-部署"><strong>方式三：Docker 部署</strong></h3><div class="llt-code readonly"><div class="language">bash</div><div class="wrapper"><pre><code class="language-bash"><span class="hljs-comment" class="hljs-comment"># 构建镜像</span>
git <span class="hljs-built_in" class="hljs-built_in">clone</span> https://github.com/HKUDS/nanobot.git
<span class="hljs-built_in" class="hljs-built_in">cd</span> nanobot
docker build -t nanobot .
​
<span class="hljs-comment" class="hljs-comment"># 初始化配置（首次）</span>
docker run -v ~/.nanobot:/root/.nanobot --<span class="hljs-built_in" class="hljs-built_in">rm</span> nanobot onboard
​
<span class="hljs-comment" class="hljs-comment"># 编辑配置文件，填入 API Key</span>
vim ~/.nanobot/config.json
​
<span class="hljs-comment" class="hljs-comment"># 启动网关（连接已启用的聊天渠道）</span>
docker run -d \
  -v ~/.nanobot:/root/.nanobot \
  -p 18790:18790 \
  --name nanobot \
  nanobot gateway</code></pre></div></div><p>镜像基于&nbsp;<code>uv:python3.12-bookworm-slim</code>，内置 Node.js 20 用于 WhatsApp bridge，体积控制得比较紧凑。<code>-v ~/.nanobot:/root/.nanobot</code>&nbsp;这个挂载是关键，配置、workspace、记忆数据全在这个目录下，容器重启不会丢。</p><h3 level="3" id="安装验证"><strong>安装验证</strong></h3><div class="llt-code readonly"><div class="language">bash</div><div class="wrapper"><pre><code class="language-bash"><span class="hljs-comment" class="hljs-comment"># 检查状态</span>
nanobot status
​
<span class="hljs-comment" class="hljs-comment"># 发一条消息测试 agent 是否正常响应</span>
nanobot agent -m <span class="hljs-string" class="hljs-string">&quot;Hello, nanobot!&quot;</span>
​
<span class="hljs-comment" class="hljs-comment"># Docker 环境下</span>
docker run -v ~/.nanobot:/root/.nanobot --<span class="hljs-built_in" class="hljs-built_in">rm</span> nanobot status
docker run -v ~/.nanobot:/root/.nanobot --<span class="hljs-built_in" class="hljs-built_in">rm</span> nanobot agent -m <span class="hljs-string" class="hljs-string">&quot;Hello!&quot;</span></code></pre></div></div><h2 level="2" id="配置与使用方法"><strong>配置与使用方法</strong></h2><p>所有配置集中在&nbsp;<code>~/.nanobot/config.json</code>&nbsp;一个文件里。</p><h3 level="3" id="Provider-配置"><strong>Provider 配置</strong></h3><p>最快的跑通路径是用 OpenRouter：</p><div class="llt-code readonly"><div class="language">json</div><div class="wrapper"><pre><code class="language-json"><span class="hljs-punctuation" class="hljs-punctuation">{</span>
  <span class="hljs-attr" class="hljs-attr">&quot;providers&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
    <span class="hljs-attr" class="hljs-attr">&quot;openrouter&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
      <span class="hljs-attr" class="hljs-attr">&quot;apiKey&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-string" class="hljs-string">&quot;sk-or-v1-xxx&quot;</span>
    <span class="hljs-punctuation" class="hljs-punctuation">}</span>
  <span class="hljs-punctuation" class="hljs-punctuation">}</span><span class="hljs-punctuation" class="hljs-punctuation">,</span>
  <span class="hljs-attr" class="hljs-attr">&quot;agents&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
    <span class="hljs-attr" class="hljs-attr">&quot;defaults&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
      <span class="hljs-attr" class="hljs-attr">&quot;model&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-string" class="hljs-string">&quot;anthropic/claude-opus-4-5&quot;</span>
    <span class="hljs-punctuation" class="hljs-punctuation">}</span>
  <span class="hljs-punctuation" class="hljs-punctuation">}</span>
<span class="hljs-punctuation" class="hljs-punctuation">}</span></code></pre></div></div><p>要跑本地模型，配 vLLM 或任何 OpenAI 兼容端点：</p><div class="llt-code readonly"><div class="language">json</div><div class="wrapper"><pre><code class="language-json"><span class="hljs-punctuation" class="hljs-punctuation">{</span>
  <span class="hljs-attr" class="hljs-attr">&quot;providers&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
    <span class="hljs-attr" class="hljs-attr">&quot;vllm&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
      <span class="hljs-attr" class="hljs-attr">&quot;apiKey&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-string" class="hljs-string">&quot;dummy&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">,</span>
      <span class="hljs-attr" class="hljs-attr">&quot;apiBase&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-string" class="hljs-string">&quot;http://localhost:8000/v1&quot;</span>
    <span class="hljs-punctuation" class="hljs-punctuation">}</span>
  <span class="hljs-punctuation" class="hljs-punctuation">}</span><span class="hljs-punctuation" class="hljs-punctuation">,</span>
  <span class="hljs-attr" class="hljs-attr">&quot;agents&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
    <span class="hljs-attr" class="hljs-attr">&quot;defaults&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
      <span class="hljs-attr" class="hljs-attr">&quot;model&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-string" class="hljs-string">&quot;meta-llama/Llama-3.1-8B-Instruct&quot;</span>
    <span class="hljs-punctuation" class="hljs-punctuation">}</span>
  <span class="hljs-punctuation" class="hljs-punctuation">}</span>
<span class="hljs-punctuation" class="hljs-punctuation">}</span></code></pre></div></div><p>如果你用的 LLM 服务不在内置列表里，<code>custom</code>&nbsp;provider 兜底，只要对方兼容 OpenAI chat completions 接口就行：</p><div class="llt-code readonly"><div class="language">json</div><div class="wrapper"><pre><code class="language-json"><span class="hljs-punctuation" class="hljs-punctuation">{</span>
  <span class="hljs-attr" class="hljs-attr">&quot;providers&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
    <span class="hljs-attr" class="hljs-attr">&quot;custom&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
      <span class="hljs-attr" class="hljs-attr">&quot;apiKey&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-string" class="hljs-string">&quot;your-api-key&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">,</span>
      <span class="hljs-attr" class="hljs-attr">&quot;apiBase&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-string" class="hljs-string">&quot;https://api.your-provider.com/v1&quot;</span>
    <span class="hljs-punctuation" class="hljs-punctuation">}</span>
  <span class="hljs-punctuation" class="hljs-punctuation">}</span>
<span class="hljs-punctuation" class="hljs-punctuation">}</span></code></pre></div></div><h3 level="3" id="渠道配置"><strong>渠道配置</strong></h3><p>以 Telegram 为例，BotFather 建个 bot，拿到 token，填进去：</p><div class="llt-code readonly"><div class="language">json</div><div class="wrapper"><pre><code class="language-json"><span class="hljs-punctuation" class="hljs-punctuation">{</span>
  <span class="hljs-attr" class="hljs-attr">&quot;channels&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
    <span class="hljs-attr" class="hljs-attr">&quot;telegram&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
      <span class="hljs-attr" class="hljs-attr">&quot;enabled&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-literal" class="hljs-literal"><span class="hljs-keyword" class="hljs-keyword">true</span></span><span class="hljs-punctuation" class="hljs-punctuation">,</span>
      <span class="hljs-attr" class="hljs-attr">&quot;token&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-string" class="hljs-string">&quot;YOUR_BOT_TOKEN&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">,</span>
      <span class="hljs-attr" class="hljs-attr">&quot;allowFrom&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">[</span><span class="hljs-string" class="hljs-string">&quot;YOUR_USER_ID&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">]</span>
    <span class="hljs-punctuation" class="hljs-punctuation">}</span>
  <span class="hljs-punctuation" class="hljs-punctuation">}</span>
<span class="hljs-punctuation" class="hljs-punctuation">}</span></code></pre></div></div><p>然后&nbsp;<code>nanobot gateway</code>&nbsp;启动网关。飞书、钉钉、Slack 都走 WebSocket 长连接，不需要公网 IP。</p><p><code>allowFrom</code>&nbsp;是白名单机制。留空表示任何人都能跟你的 bot 对话，生产环境务必填上受信用户 ID。</p><h3 level="3" id="MCP-工具接入"><strong>MCP 工具接入</strong></h3><div class="llt-code readonly"><div class="language">json</div><div class="wrapper"><pre><code class="language-json"><span class="hljs-punctuation" class="hljs-punctuation">{</span>
  <span class="hljs-attr" class="hljs-attr">&quot;tools&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
    <span class="hljs-attr" class="hljs-attr">&quot;mcpServers&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
      <span class="hljs-attr" class="hljs-attr">&quot;filesystem&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
        <span class="hljs-attr" class="hljs-attr">&quot;command&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-string" class="hljs-string">&quot;npx&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">,</span>
        <span class="hljs-attr" class="hljs-attr">&quot;args&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">[</span><span class="hljs-string" class="hljs-string">&quot;-y&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">,</span> <span class="hljs-string" class="hljs-string">&quot;@modelcontextprotocol/server-filesystem&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">,</span> <span class="hljs-string" class="hljs-string">&quot;/path/to/dir&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">]</span>
      <span class="hljs-punctuation" class="hljs-punctuation">}</span>
    <span class="hljs-punctuation" class="hljs-punctuation">}</span>
  <span class="hljs-punctuation" class="hljs-punctuation">}</span>
<span class="hljs-punctuation" class="hljs-punctuation">}</span></code></pre></div></div><p>支持 stdio 和 HTTP 两种传输模式。启动时自动发现并注册 MCP 工具，LLM 调用时和内置工具没有区别。</p><h3 level="3" id="安全配置"><strong>安全配置</strong></h3><div class="llt-code readonly"><div class="language">json</div><div class="wrapper"><pre><code class="language-json"><span class="hljs-punctuation" class="hljs-punctuation">{</span>
  <span class="hljs-attr" class="hljs-attr">&quot;tools&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-punctuation" class="hljs-punctuation">{</span>
    <span class="hljs-attr" class="hljs-attr">&quot;restrictToWorkspace&quot;</span><span class="hljs-punctuation" class="hljs-punctuation">:</span> <span class="hljs-literal" class="hljs-literal"><span class="hljs-keyword" class="hljs-keyword">true</span></span>
  <span class="hljs-punctuation" class="hljs-punctuation">}</span>
<span class="hljs-punctuation" class="hljs-punctuation">}</span></code></pre></div></div><p><code>restrictToWorkspace</code>&nbsp;开启后，agent 的 shell 执行、文件读写全部限制在 workspace 目录内，防止路径穿越。生产部署建议开启。</p><p>1. <strong>HKUDS/nanobot – “Ultra‑Lightweight Personal AI Assistant” (Python, multi‑channel)</strong></p><p>2. <strong>nanobot-ai/nanobot – “Build MCP Agents” (Go, MCP host)</strong></p><p>You can skip to the one you actually meant.</p><p>---</p><p>## 0. Which “nanobot” do you mean?</p><p>- <strong>HKUDS/nanobot</strong></p><p>- URL: <code>https://github.com/HKUDS/nanobot</code></p><p>- Language: Python</p><p>- What it is: A personal AI assistant that can talk via <strong>Telegram / Discord / WhatsApp / Slack / Email / QQ / Feishu / DingTalk / Mochat</strong> etc.</p><p>- Config file: <code>~/.nanobot/config.json</code></p><p>- <strong>nanobot-ai/nanobot</strong></p><p>- URL: <code>https://github.com/nanobot-ai/nanobot</code></p><p>- Language: Go</p><p>- What it is: A standalone <strong>MCP host</strong> for building agents with MCP/MCP‑UI (e.g. Blackjack, Hugging Face, shopping agents)</p><p>- Config file: <code>nanobot.yaml</code> or a directory of <code>.md</code> agent files</p><p>If you’re not sure, check the repo URL. The guide below is split into <strong>Part A (HKUDS)</strong> and <strong>Part B (nanobot-ai)</strong>.</p><p>---</p><h3 level="3" id="-Part-A--HKUDSnanobot-StepbyStep-Config-configjson">## Part A – HKUDS/nanobot: Step‑by‑Step Config (config.json)</h3><p>### Overview of the flow</p><p>```mermaid</p><p>flowchart LR</p><p>A[Install nanobot] --&gt; B[Run nanobot onboard]</p><p>B --&gt; C[Edit ~/.nanobot/config.json]</p><p>C --&gt; D[Add providers]</p><p>C --&gt; E[Add agents]</p><p>C --&gt; F[Add channels]</p><p>D --&gt; G[Test with nanobot agent]</p><p>E --&gt; G</p><p>F --&gt; H[Run nanobot gateway]</p><p>H --&gt; I[Use from Telegram/Discord/Slack/...]</p><p>```</p><p>---</p><p>### Step 1 – Install nanobot</p><p>You have three options (from the README):</p><p>1. <strong>Install from source (latest, recommended for dev)</strong></p><p>```bash</p><p>git clone <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/HKUDS/nanobot.git">https://github.com/HKUDS/nanobot.git</a></p><p>cd nanobot</p><p>pip install -e .</p><p>```</p><p>2. <strong>Install with uv (stable, fast)</strong></p><p>```bash</p><p>uv tool install nanobot-ai</p><p>```</p><p>3. <strong>Install from PyPI (stable)</strong></p><p>```bash</p><p>pip install nanobot-ai</p><p>```</p><p>After install, you should have the <code>nanobot</code> CLI on your <code>PATH</code>.</p><p>---</p><p>### Step 2 – Initialize config &amp; workspace</p><p>Run the onboarding command (this creates <code>~/.nanobot</code> and a basic config):</p><p>```bash</p><p>nanobot onboard</p><p>```</p><p>This creates <code>~/.nanobot/config.json</code> and a workspace directory.</p><p>---</p><p>### Step 3 – Basic config.json structure</p><p>Open the config:</p><p>```bash</p><p>vim ~/.nanobot/config.json</p><p># or</p><p>code ~/.nanobot/config.json</p><p>```</p><p>The minimal structure you care about is:</p><p>```json</p><p>{</p><p>&quot;providers&quot;: { ... },</p><p>&quot;agents&quot;: { ... },</p><p>&quot;channels&quot;: { ... }</p><p>}</p><p>```</p><p>- *<code>providers</code>** – LLM providers (OpenRouter, OpenAI, Anthropic, DeepSeek, Qwen, MiniMax, vLLM, etc.)</p><p>- *<code>agents</code>** – Agent defaults (which model, temperature, etc.)</p><p>- *<code>channels</code>** – Chat channels (Telegram, Discord, Slack, Email, etc.)</p><p>---</p><p>### Step 4 – Configure providers (LLM backend)</p><p>#### Option 1 – Use OpenRouter (recommended by the authors)</p><p>Example from README:</p><p>```json</p><p>{</p><p>&quot;providers&quot;: {</p><p>&quot;openrouter&quot;: {</p><p>&quot;apiKey&quot;: &quot;sk-or-v1-xxx&quot;</p><p>}</p><p>},</p><p>&quot;agents&quot;: {</p><p>&quot;defaults&quot;: {</p><p>&quot;model&quot;: &quot;anthropic/claude-opus-4-5&quot;</p><p>}</p><p>}</p><p>}</p><p>```</p><p>- Get your API key from <code>https://openrouter.ai</code>.</p><p>#### Option 2 – Use a local model with vLLM</p><p>1. Start vLLM:</p><p>```bash</p><p>vllm serve meta-llama/Llama-3.1-8B-Instruct --port 8000</p><p>```</p><p>2. Configure nanobot to use it:</p><p>```json</p><p>{</p><p>&quot;providers&quot;: {</p><p>&quot;vllm&quot;: {</p><p>&quot;apiKey&quot;: &quot;dummy&quot;,</p><p>&quot;apiBase&quot;: &quot;<a target="_blank" rel="noopener noreferrer nofollow" href="http://localhost:8000/v1">http://localhost:8000/v1</a>&quot;</p><p>}</p><p>},</p><p>&quot;agents&quot;: {</p><p>&quot;defaults&quot;: {</p><p>&quot;model&quot;: &quot;meta-llama/Llama-3.1-8B-Instruct&quot;</p><p>}</p><p>}</p><p>}</p><p>```</p><p>You can mix multiple providers if you want (e.g. <code>openrouter</code>, <code>openai</code>, <code>deepseek</code>, <code>dashscope</code>, <code>zhipu</code>, <code>moonshot</code>, <code>minimax</code>, <code>groq</code>, <code>gemini</code>, etc.).</p><p>---</p><p>### Step 5 – (Optional) Tune agent defaults</p><p>Under <code>agents.defaults</code> you can set things like:</p><p>```json</p><p>&quot;agents&quot;: {</p><p>&quot;defaults&quot;: {</p><p>&quot;model&quot;: &quot;anthropic/claude-opus-4-5&quot;,</p><p>&quot;temperature&quot;: 0.7,</p><p>&quot;tools&quot;: {</p><p>&quot;restrictToWorkspace&quot;: true</p><p>}</p><p>}</p><p>}</p><p>```</p><p>- <code>tools.restrictToWorkspace: true</code> is recommended for production to sandbox file/shell tools to the workspace directory.</p><p>---</p><p>### Step 6 – Add chat channels (Telegram / Discord / Slack / Email / etc.)</p><p>You can enable one or more channels under the <code>&quot;channels&quot;</code> key.</p><p>#### 6.1 Telegram (recommended)</p><p>1. Create a Telegram bot via <strong>@BotFather</strong> → <code>/newbot</code> and copy the token.</p><p>2. Get your <strong>user ID</strong> from Telegram settings (shown as <code>@yourUserId</code>).</p><p>3. Add to <code>config.json</code>:</p><p>```json</p><p>{</p><p>&quot;channels&quot;: {</p><p>&quot;telegram&quot;: {</p><p>&quot;enabled&quot;: true,</p><p>&quot;token&quot;: &quot;YOUR_BOT_TOKEN&quot;,</p><p>&quot;allowFrom&quot;: [&quot;YOUR_USER_ID&quot;]</p><p>}</p><p>}</p><p>}</p><p>```</p><p>4. Start the gateway:</p><p>```bash</p><p>nanobot gateway</p><p>```</p><p>Now talk to your bot on Telegram.</p><p>#### 6.2 Discord</p><p>1. Create a Discord app + bot:</p><p>- Go to <a target="_blank" rel="noopener noreferrer nofollow" href="https://discord.com/developers/applications">https://discord.com/developers/applications</a></p><p>- Create application → Bot → Add Bot → copy <strong>bot token</strong>.</p><p>2. Enable <strong>MESSAGE CONTENT INTENT</strong> (and optionally <strong>SERVER MEMBERS INTENT</strong>) in the Bot tab.</p><p>3. Get your user ID: enable Developer Mode in Discord, right‑click your avatar → Copy User ID.</p><p>4. Config:</p><p>```json</p><p>{</p><p>&quot;channels&quot;: {</p><p>&quot;discord&quot;: {</p><p>&quot;enabled&quot;: true,</p><p>&quot;token&quot;: &quot;YOUR_BOT_TOKEN&quot;,</p><p>&quot;allowFrom&quot;: [&quot;YOUR_USER_ID&quot;]</p><p>}</p><p>}</p><p>}</p><p>```</p><p>5. Invite the bot using OAuth2 → URL Generator, scopes <code>bot</code>, permissions “Send Messages, Read Message History”.</p><p>6. Run <code>nanobot gateway</code>.</p><p>#### 6.3 Slack</p><p>1. Create a Slack app (from scratch) in your workspace.</p><p>2. Configure:</p><p>- <strong>Socket Mode</strong>: ON → generate an <strong>App‑Level Token</strong> with <code>connections:write</code> scope → copy <code>xapp-...</code>.</p><p>- <strong>OAuth &amp; Permissions</strong>: add bot scopes <code>chat:write</code>, <code>reactions:write</code>, <code>app_mentions:read</code>.</p><p>- <strong>Event Subscriptions</strong>: ON → subscribe to <code>message.im</code>, <code>message.channels</code>, <code>app_mention</code>.</p><p>- <strong>App Home</strong>: enable Messages Tab and allow slash commands/messages.</p><p>3. Install the app → copy the <strong>Bot Token</strong> <code>xoxb-...</code>).</p><p>4. Config:</p><p>```json</p><p>{</p><p>&quot;channels&quot;: {</p><p>&quot;slack&quot;: {</p><p>&quot;enabled&quot;: true,</p><p>&quot;botToken&quot;: &quot;xoxb-...&quot;,</p><p>&quot;appToken&quot;: &quot;xapp-...&quot;,</p><p>&quot;groupPolicy&quot;: &quot;mention&quot;</p><p>}</p><p>}</p><p>}</p><p>```</p><p><code>groupPolicy</code> can be <code>&quot;mention&quot;</code>, <code>&quot;open&quot;</code>, or <code>&quot;allowlist&quot;</code>.</p><p>5. Run <code>nanobot gateway</code>.</p><p>#### 6.4 Email (IMAP + SMTP)</p><p>Example for Gmail (you need an app password, not your main password):</p><p>```json</p><p>{</p><p>&quot;channels&quot;: {</p><p>&quot;email&quot;: {</p><p>&quot;enabled&quot;: true,</p><p>&quot;consentGranted&quot;: true,</p><p>&quot;imapHost&quot;: &quot;<a target="_blank" rel="noopener noreferrer nofollow" href="http://imap.gmail.com">imap.gmail.com</a>&quot;,</p><p>&quot;imapPort&quot;: 993,</p><p>&quot;imapUsername&quot;: &quot;<a target="_blank" rel="noopener noreferrer nofollow" href="mailto:my-nanobot@gmail.com">my-nanobot@gmail.com</a>&quot;,</p><p>&quot;imapPassword&quot;: &quot;your-app-password&quot;,</p><p>&quot;smtpHost&quot;: &quot;<a target="_blank" rel="noopener noreferrer nofollow" href="http://smtp.gmail.com">smtp.gmail.com</a>&quot;,</p><p>&quot;smtpPort&quot;: 587,</p><p>&quot;smtpUsername&quot;: &quot;<a target="_blank" rel="noopener noreferrer nofollow" href="mailto:my-nanobot@gmail.com">my-nanobot@gmail.com</a>&quot;,</p><p>&quot;smtpPassword&quot;: &quot;your-app-password&quot;,</p><p>&quot;fromAddress&quot;: &quot;<a target="_blank" rel="noopener noreferrer nofollow" href="mailto:my-nanobot@gmail.com">my-nanobot@gmail.com</a>&quot;,</p><p>&quot;allowFrom&quot;: [&quot;<a target="_blank" rel="noopener noreferrer nofollow" href="mailto:your-real-email@gmail.com">your-real-email@gmail.com</a>&quot;]</p><p>}</p><p>}</p><p>}</p><p>```</p><p>- Set <code>consentGranted: true</code> to allow mailbox access.</p><p>- <code>allowFrom</code> can be left empty to accept all senders, or restricted.</p><p>- Then run <code>nanobot gateway</code>.</p><p>Similar patterns exist for <strong>WhatsApp, Feishu, QQ, DingTalk, Mochat</strong> etc. in the README.</p><p>---</p><p>### Step 7 – Test your config</p><p>1. <strong>Quick CLI test</strong>:</p><p>```bash</p><p>nanobot agent -m &quot;What is 2+2?&quot;</p><p>```</p><p>You should see the agent reply using your configured LLM.</p><p>2. <strong>If you enabled channels</strong>, start the gateway:</p><p>```bash</p><p>nanobot gateway</p><p>```</p><p>Then send a message to your Telegram bot / Discord bot / Slack app / email address, etc.</p><p>3. <strong>Check status</strong>:</p><p>```bash</p><p>nanobot status</p><p>```</p><p>This shows providers, channels, and other runtime info.</p><p>---</p><p>### Step 8 – (Optional) Use Docker</p><p>If you prefer Docker, the README shows the pattern:</p><p>```bash</p><p># Build</p><p>docker build -t nanobot .</p><p># Initialize config (first time)</p><p>docker run -v ~/.nanobot:/root/.nanobot --rm nanobot onboard</p><p># Edit config on host</p><p>vim ~/.nanobot/config.json</p><p># Run gateway</p><p>docker run -v ~/.nanobot:/root/.nanobot -p 18790:18790 nanobot gateway</p><p>```</p><p>---</p><p>## Part B – nanobot-ai/nanobot: Step‑by‑Step Config (MCP host)</p><p>If you meant the <strong>MCP</strong> project <code>github.com/nanobot-ai/nanobot</code>), here’s a concise guide.</p><p>### Step 1 – Install the CLI</p><p>Recommended (Homebrew):</p><p>```bash</p><p>brew install nanobot-ai/tap/nanobot</p><p>```</p><p>This gives you the <code>nanobot</code> CLI for running an MCP host.</p><p>---</p><p>### Step 2 – Set LLM API keys</p><p>Set environment variables for your provider:</p><p>```bash</p><p># For OpenAI models</p><p>export OPENAI_API_KEY=&quot;sk-...&quot;</p><p># For Anthropic models</p><p>export ANTHROPIC_API_KEY=&quot;sk-ant-...&quot;</p><p>```</p><p>Nanobot automatically selects the provider based on the model name you use in the config.</p><p>---</p><p>### Step 3 – Single‑file config (nanobot.yaml)</p><p>Create a file <code>nanobot.yaml</code> in your project:</p><p>```yaml</p><p>agents:</p><p>dealer:</p><p>name: Blackjack Dealer</p><p>model: gpt-4.1</p><p>mcpServers:</p><p>- blackjackmcp</p><p>mcpServers:</p><p>blackjackmcp:</p><p>url: <a target="_blank" rel="noopener noreferrer nofollow" href="https://blackjack.nanobot.ai/mcp">https://blackjack.nanobot.ai/mcp</a></p><p>```</p><p>Then run:</p><p>```bash</p><p>nanobot run ./nanobot.yaml</p><p>```</p><p>The UI will be available at <code>http://localhost:8080</code>.</p><p>You can define multiple agents and multiple MCP servers in this single file.</p><p>---</p><p>### Step 4 – Directory‑based config (agents/*.md)</p><p>If you prefer a more modular setup, use a directory:</p><p>```</p><p>my-config/</p><p>├── agents/</p><p>│ ├── <a target="_blank" rel="noopener noreferrer nofollow" href="http://main.md">main.md</a> # becomes the default agent</p><p>│ └── <a target="_blank" rel="noopener noreferrer nofollow" href="http://helper.md">helper.md</a></p><p>└── mcp-servers.yaml # or mcp-servers.json</p><p>```</p><p><strong>agents/</strong><a target="_blank" rel="noopener noreferrer nofollow" href="http://main.md"><strong>main.md</strong></a> (YAML front‑matter + Markdown body):</p><p>```yaml</p><p>---</p><p>name: Shopping Assistant</p><p>model: claude-3-7-sonnet-latest</p><p>mcpServers:</p><p>- store</p><p>temperature: 0.7</p><p>---</p><p>You are a helpful shopping assistant. Help users find products and answer questions.</p><p>```</p><p><strong>mcp-servers.yaml</strong>:</p><p>```yaml</p><p>store:</p><p>url: <a target="_blank" rel="noopener noreferrer nofollow" href="https://example.com/mcp">https://example.com/mcp</a></p><p>headers:</p><p>Authorization: Bearer ${MY_TOKEN}</p><p>```</p><p>Then run:</p><p>```bash</p><p>nanobot run ./my-config/</p><p>```</p><p>Nanobot will:</p><p>- Treat each <code>.md</code> in <code>agents/</code> as an agent.</p><p>- Use <code>agents/main.md</code> as the default entrypoint if it exists.</p><p>---</p><p>### Step 5 – Use the agent</p><p>Once <code>nanobot run</code> is up:</p><p>1. Open <code>http://localhost:8080</code> in your browser.</p><p>2. Use the chat UI to talk to your agent.</p><p>3. The agent will call the configured MCP servers automatically (e.g. Blackjack MCP, Hugging Face MCP, Shopify, etc.).</p><p>---</p><p></p><h3 level="3" id="下面我在你已经有的配置步骤基础上结合仓库源码和-README对-HKUDSnanobot-做一个更系统的进一步解释讲清楚它到底是什么怎么跑起来核心模块怎么工作以及怎么根据自己需求改配置">下面我在你已经有的配置步骤基础上，结合仓库源码和 README，对 **HKUDS/nanobot** 做一个更系统的“进一步解释”，讲清楚它到底是什么、怎么跑起来、核心模块怎么工作，以及怎么根据自己需求改配置。</h3><p>---</p><p>## 1. nanobot 是什么？</p><p>**定位：极简个人 AI 助手框架（~4k 行核心代码）**</p><p>- 核心代码只有大约 **3,587 行**，官方称比 Clawdbot 的 430k+ 行小 99%。</p><p>- 目标：</p><p>- 保留核心 Agent 能力（对话、工具调用、记忆等），</p><p>- 但代码尽量少、好读、好改，方便研究和二次开发。</p><p>- 典型能力（README 里列的）：</p><p>- 24/7 实时行情分析</p><p>- 全栈软件工程师辅助</p><p>- 智能日常作息管理（日程、提醒）</p><p>- 个人知识助手（检索、记忆、推理）</p><p>**一句话概括：**</p><p>nanobot 是一个“极简但功能完整”的个人 Agent 框架，把多平台聊天（Telegram / Discord / Slack / 飞书 / 钉钉 / QQ / WhatsApp / Email / Mochat 等）和多 LLM 提供方统一封装起来，方便你当“私人 AI 助手”用。</p><p>---</p><p>## 2. 整体架构长什么样？</p><p>虽然 README 里没有单独章节，但仓库里有 <code>nanobot_arch.png</code> 架构图，配合源码目录结构可以理解整个系统。</p><p>### 2.1 目录结构（核心模块）</p><p>```text</p><p>nanobot/</p><p>├── agent/ # 核心_agent_逻辑（主循环、上下文、记忆、工具等）</p><p>│ ├── <a target="_blank" rel="noopener noreferrer nofollow" href="http://loop.py">loop.py</a> # Agent 主循环：LLM &lt;-&gt; 工具调用</p><p>│ ├── <a target="_blank" rel="noopener noreferrer nofollow" href="http://context.py">context.py</a> # 提示构建（系统提示、历史消息等）</p><p>│ ├── <a target="_blank" rel="noopener noreferrer nofollow" href="http://memory.py">memory.py</a> # 持久化记忆</p><p>│ ├── <a target="_blank" rel="noopener noreferrer nofollow" href="http://skills.py">skills.py</a> # 技能加载器</p><p>│ ├── <a target="_blank" rel="noopener noreferrer nofollow" href="http://subagent.py">subagent.py</a> # 后台子任务执行</p><p>│ └── tools/ # 内置工具（文件、shell、spawn 等）</p><p>├── skills/ # 打包好的技能：github、weather、tmux 等</p><p>├── channels/ # 各种聊天通道集成（Telegram/Discord/Slack/...）</p><p>├── bus/ # 消息路由（不同通道的消息统一分发）</p><p>├── cron/ # 定时任务（类似 cron）</p><p>├── heartbeat/ # 主动“唤醒”机制（定时自检）</p><p>├── providers/ # LLM 提供方封装（OpenRouter、Anthropic、OpenAI 等）</p><p>├── session/ # 会话管理</p><p>├── config/ # 配置模型（<a target="_blank" rel="noopener noreferrer nofollow" href="http://schema.py">schema.py</a> 定义所有配置结构）</p><p>└── cli/ # 命令行入口：onboard、agent、gateway、status 等</p><p>```</p><p>### 2.2 用一张图理解数据流</p><p>下面是一个简化版的数据流和组件关系（从你在 App 里说话，到 Agent 处理，再到回复）：</p><p>```mermaid</p><p>flowchart LR</p><p>U[用户] --&gt;|发消息| C[Channels: Telegram/Discord/Slack/Email/...]</p><p>C --&gt;|统一消息结构| B[Bus: 消息路由]</p><p>B --&gt;|调度| A[Agent: agent/<a target="_blank" rel="noopener noreferrer nofollow" href="http://loop.py">loop.py</a>]</p><p>A --&gt;|调用| P[Providers: OpenRouter/DeepSeek/Qwen/...]</p><p>P --&gt;|LLM 响应| A</p><p>A --&gt;|工具调用| T[Tools: 文件/Shell/技能]</p><p>T --&gt;|结果| A</p><p>A --&gt;|生成回复| B</p><p>B --&gt;|按会话路由| C</p><p>C --&gt;|回复| U</p><p>```</p><p>**理解要点：**</p><p>- **Channels** 只负责“怎么接入聊天平台”，消息格式统一丢给 **Bus**。</p><p>- **Bus** 再把消息交给 **Agent**，Agent 不关心具体是哪个平台来的。</p><p>- **Agent** 通过 **Providers** 调 LLM，通过 **Tools/Skills** 调各种能力。</p><p>- 这样你就可以“一套 Agent 逻辑 + 多个通道”复用。</p><p>---</p><p>## 3. 配置文件到底在干什么？</p><p>配置文件 <code>~/.nanobot/config.json</code> 对应的是 <code>config/schema.py</code> 里的 Pydantic 模型。</p><p>顶层结构大致是：</p><p>```python</p><p>class Config(BaseSettings):</p><p>agents: AgentsConfig # Agent 默认行为</p><p>channels: ChannelsConfig # 各聊天通道配置</p><p>providers: ProvidersConfig # 各 LLM 提供方配置</p><p>gateway: GatewayConfig # gateway 服务配置</p><p>tools: ToolsConfig # 工具相关配置</p><p>```</p><p>### 3.1 providers：怎么选 LLM 后端</p><p><code>ProvidersConfig</code> 里预定义了很多提供方：</p><p>- <code>openrouter</code>：推荐，聚合几乎所有模型（Claude、GPT、Gemini、DeepSeek、Qwen 等）。</p><p>- <code>anthropicopenaideepseekgroqgeminiminimaxmoonshotdashscope</code>（通义千问）<code>zhipuaihubmixvllm</code> 等。</p><p>- <code>custom</code>：任意 OpenAI 兼容 API。</p><p>**ProviderConfig 结构**：</p><p>```python</p><p>class ProviderConfig(BaseModel):</p><p>api_key: str = &quot;&quot;</p><p>api_base: str | None = None</p><p>extra_headers: dict[str, str] | None = None</p><p>```</p><p>对应的 JSON 片段（README 示例）：</p><p>```json</p><p>{</p><p>&quot;providers&quot;: {</p><p>&quot;openrouter&quot;: {</p><p>&quot;apiKey&quot;: &quot;sk-or-v1-xxx&quot;</p><p>}</p><p>},</p><p>&quot;agents&quot;: {</p><p>&quot;defaults&quot;: {</p><p>&quot;model&quot;: &quot;anthropic/claude-opus-4-5&quot;</p><p>}</p><p>}</p><p>}</p><p>```</p><p>**工作流程：**</p><p>1. 你在 <code>agents.defaults.model</code> 里写上要用的模型名，比如 <code>&quot;anthropic/claude-opus-4-5&quot;</code>。</p><p>2. nanobot 根据 <code>ProvidersConfig</code> + <code>registry.py</code> 里的关键词匹配，自动选择对应的提供方。</p><p>3. 如果是 OpenRouter 这种“网关型”提供方，会自动拼接前缀，比如 <code>openrouter/anthropic/claude-opus-4-5</code>。</p><p>**本地模型（vLLM）示例**：</p><p>```bash</p><p>vllm serve meta-llama/Llama-3.1-8B-Instruct --port 8000</p><p>```</p><p>```json</p><p>{</p><p>&quot;providers&quot;: {</p><p>&quot;vllm&quot;: {</p><p>&quot;apiKey&quot;: &quot;dummy&quot;,</p><p>&quot;apiBase&quot;: &quot;<a target="_blank" rel="noopener noreferrer nofollow" href="http://localhost:8000/v1">http://localhost:8000/v1</a>&quot;</p><p>}</p><p>},</p><p>&quot;agents&quot;: {</p><p>&quot;defaults&quot;: {</p><p>&quot;model&quot;: &quot;meta-llama/Llama-3.1-8B-Instruct&quot;</p><p>}</p><p>}</p><p>}</p><p>```</p><p>### 3.2 agents：Agent 默认行为</p><p><code>AgentsConfig</code> 目前主要是 <code>defaults</code>：</p><p>```python</p><p>class AgentDefaults(BaseModel):</p><p>workspace: str = &quot;~/.nanobot/workspace&quot;</p><p>model: str = &quot;anthropic/claude-opus-4-5&quot;</p><p>max_tokens: int = 8192</p><p>temperature: float = 0.7</p><p>max_tool_iterations: int = 20</p><p>memory_window: int = 50</p><p>```</p><p>你可以理解为：</p><p>- <code>workspace</code>：Agent 所有文件操作的“根目录”，工具会被限制在这个目录里（如果开了沙箱）。</p><p>- <code>model</code>：默认使用的模型（会被 providers 匹配）。</p><p>- <code>memory_window</code>：保留多少轮对话历史作为“短期记忆”。</p><p>### 3.3 channels：多平台通道配置</p><p><code>ChannelsConfig</code> 定义了所有支持的通道：</p><p>```python</p><p>class ChannelsConfig(BaseModel):</p><p>whatsapp: WhatsAppConfig</p><p>telegram: TelegramConfig</p><p>discord: DiscordConfig</p><p>feishu: FeishuConfig</p><p>mochat: MochatConfig</p><p>dingtalk: DingTalkConfig</p><p>email: EmailConfig</p><p>slack: SlackConfig</p><p>qq: QQConfig</p><p>```</p><p>每个通道都有一个 <code>enabled</code> 开关和一堆连接参数，比如：</p><p>- Telegram<code>token</code> + <code>allow_from</code>。</p><p>- Discord<code>token</code> + <code>intents</code> + <code>allow_from</code>。</p><p>- Slack<code>bot_token</code> + <code>app_token</code> + <code>group_policy</code>。</p><p>- Email：IMAP/SMTP 相关配置 + <code>consent_grantedauto_reply_enabled</code> 等。</p><p>- 飞书、钉钉、QQ、Mochat 等，基本都是 AppID/AppSecret 或 Token + <code>allow_from</code>。</p><p>**关键点：**</p><p>- <code>allow_from</code> 是白名单：</p><p>- 为空：允许所有人使用。</p><p>- 非空：只允许列表里的用户 ID / 手机号 / 邮箱 等访问。</p><p>- 对于生产环境，强烈建议配置 <code>allow_from</code>，避免被别人滥用。</p><p>### 3.4 tools：工具权限与沙箱</p><p><code>ToolsConfig</code> 里有一个重要开关<code>restrict_to_workspace</code>：</p><p>```python</p><p>class ToolsConfig(BaseModel):</p><p>web: WebToolsConfig</p><p>exec: ExecToolConfig</p><p>restrict_to_workspace: bool = False</p><p>```</p><p>- 为 <code>true</code> 时，所有工具（文件读写、shell 执行等）都只能访问 <code>workspace</code> 目录，防止路径穿越攻击。</p><p>- 对应 JSON：</p><p>```json</p><p>{</p><p>&quot;tools&quot;: {</p><p>&quot;restrictToWorkspace&quot;: true</p><p>}</p><p>}</p><p>```</p><p>README 里也建议在生产环境开启。</p><p>---</p><p>## 4. 从“启动流程”再看一遍系统</p><p>结合 README 的 CLI 说明，可以按“启动流程”理解系统：</p><p>### 4.1 初始化<code>nanobot onboard</code></p><p>```bash</p><p>nanobot onboard</p><p>```</p><p>- 创建 <code>~/.nanobot</code> 目录。</p><p>- 生成初始 <code>config.json</code> 和 <code>workspace</code> 目录。</p><p>- 相当于“安装向导”。</p><p>### 4.2 交互式对话<code>nanobot agent</code></p><p>```bash</p><p>nanobot agent -m &quot;What is 2+2?&quot;</p><p>nanobot agent # 交互模式</p><p>```</p><p>- 直接在 CLI 里和 Agent 聊天。</p><p>- 不需要启动 gateway，适合调试和简单使用。</p><p>### 4.3 多通道网关<code>nanobot gateway</code></p><p>```bash</p><p>nanobot gateway</p><p>```</p><p>- 启动一个网关服务，监听配置中启用的所有通道（Telegram/Discord/Slack/Email 等）。</p><p>- 各通道的消息通过 bus 转发给 Agent，再由 Agent 统一处理。</p><p>- 如果你希望“一个机器人，多平台统一聊天”，就用 gateway。</p><p>### 4.4 状态与定时任务<code>nanobot status</code> / <code>nanobot cron</code></p><p>- <code>nanobot status</code>：查看当前配置、提供方状态、通道状态等。</p><p>- <code>nanobot cron</code>：管理定时任务（类似 cron）：</p><p>```bash</p><p>nanobot cron add --name &quot;daily&quot; --message &quot;Good morning!&quot; --cron &quot;0 9 * * *&quot;</p><p>nanobot cron list</p><p>nanobot cron remove &lt;job_id&gt;</p><p>```</p><p>---</p><p>## 5. 实际配置时的一些“坑”和建议</p><p>结合 README 和 schema，再补充几个实战要点：</p><p>### 5.1 多 Provider 怎么选？</p><p>- 想要“全球模型一把梭”：</p><p>- 用 <code>openrouter</code>，一个 key 访问 Claude / GPT / Gemini / DeepSeek / Qwen 等。</p><p>- 在国内想用国产模型：</p><p>- DeepSeek、Moonshot/Kimi、Qwen（通义千问）、GLM（智谱）、MiniMax 等，都有对应提供方。</p><p>- 注意部分提供方需要设置 <code>apiBase</code>，比如：</p><p>- Zhipu Coding Plan<code>&quot;apiBase&quot;: &quot;https://open.bigmodel.cn/api/coding/paas/v4&quot;</code><a target="_blank" rel="noopener noreferrer nofollow" href="https://open.bigmodel.cn/api/coding/paas/v4&quot;`。">。</a></p><p>- MiniMax 中国大陆平台<code>&quot;apiBase&quot;: &quot;https://api.minimaxi.com/v1&quot;</code><a target="_blank" rel="noopener noreferrer nofollow" href="https://api.minimaxi.com/v1&quot;`。">。</a></p><p>### 5.2 通道安全配置</p><p>- **一定要设置 <code>allow_from</code>**，尤其是：</p><p>- Telegram：只允许自己的 user_id。</p><p>- Discord：只允许自己的用户 ID。</p><p>- Slack：只允许自己的工作区成员 / 特定频道。</p><p>- Email 通道：</p><p>- 给机器人一个专用邮箱。</p><p>- 开启 2FA，用“应用专用密码”而不是真实密码。</p><p>- <code>consentGranted</code> 要设为 <code>true</code>，否则不会真正访问邮箱。</p><p>### 5.3 本地模型与 vLLM</p><p>- vLLM 本质上是暴露一个 OpenAI 兼容 API，nanobot 通过 <code>vllm</code> 提供方对接。</p><p>- <code>apiKey</code> 可以随便填（本地不校验），但 <code>apiBase</code> 要指向你的 vLLM 服务地址。</p><p>### 5.4 Docker 部署时的注意事项</p><p>README 给的 Docker 命令：</p><p>```bash</p><p>docker build -t nanobot .</p><p>docker run -v ~/.nanobot:/root/.nanobot --rm nanobot onboard</p><p>vim ~/.nanobot/config.json</p><p>docker run -v ~/.nanobot:/root/.nanobot -p 18790:18790 nanobot gateway</p><p>```</p><p>- <code>-v ~/.nanobot:/root/.nanobot</code>：把本地配置目录挂到容器里，这样：</p><p>- 你在宿主机改 <code>config.json</code>，容器里立刻生效。</p><p>- workspace 目录也在宿主机持久化。</p><p>- 生产环境建议：</p><p>- 把 <code>config.json</code> 权限收紧（600），避免 key 泄露。</p><p>- 使用环境变量注入 API key，而不是写死在 JSON 里。</p><p>---</p><p>## 6. 如果你打算二次开发 / 研究</p><p>nanobot 代码量很小，特别适合作为“研究用 Agent 框架”：</p><p>- <code>agent/loop.py</code>：Agent 主循环，理解“思考-调用工具-再思考”的关键。</p><p>- <code>agent/memory.py</code>：记忆管理，如何把长期/短期记忆拼进 prompt。</p><p>- <code>agent/tools/</code>：内置工具实现，你可以参考写自己的工具。</p><p>- <code>skills/</code>：官方打包的一些技能（github、weather、tmux 等），可以作为“技能开发模板”。</p><p>- <code>providers/registry.py</code>：提供方注册表，你可以按 README 里的 2 步新增自己的提供方。</p><p>---</p><p></p><h3 level="3" id="准确安全且易于上手的配置示例和指南">准确、安全且易于上手的配置示例和指南</h3><p>香港大学数据科学研究所（HKUDS）的 <code>nanobot</code> 项目是一个轻量级的个人AI助手框架。根据您的需求，我为您准备了一份仅启用 <strong>Telegram</strong> 和 <strong>Email</strong> 渠道的完整 <code>config.json</code> 配置示例，并详细解释了每一部分的作用。</p><p>### 完整 <code>config.json</code> 示例</p><p>请将以下内容保存为 <code>~/.nanobot/config.json</code> 文件，并将所有 <code>&lt;&lt;...&gt;&gt;</code> 占位符替换为您自己的实际信息。</p><p>```json</p><p>{</p><p>// =======================</p><p>// 1. LLM 提供方配置</p><p>// =======================</p><p>&quot;providers&quot;: {</p><p>// 推荐：通过 OpenRouter 聚合访问几乎所有主流模型</p><p>&quot;openrouter&quot;: {</p><p>&quot;apiKey&quot;: &quot;&lt;&lt;YOUR_OPENROUTER_API_KEY&gt;&gt;&quot;</p><p>},</p><p>// 示例：直接使用 DeepSeek API</p><p>&quot;deepseek&quot;: {</p><p>&quot;apiKey&quot;: &quot;&lt;&lt;YOUR_DEEPSEEK_API_KEY&gt;&gt;&quot;,</p><p>&quot;apiBase&quot;: &quot;<a target="_blank" rel="noopener noreferrer nofollow" href="https://api.deepseek.com/v1">https://api.deepseek.com/v1</a>&quot;</p><p>}</p><p>},</p><p>// =======================</p><p>// 2. Agent 默认行为配置</p><p>// =======================</p><p>&quot;agents&quot;: {</p><p>&quot;defaults&quot;: {</p><p>// 指定默认使用的模型，这里的名称会被 providers 匹配</p><p>&quot;model&quot;: &quot;anthropic/claude-opus-4-5&quot;, // 对应 OpenRouter 中的模型名</p><p>// &quot;model&quot;: &quot;deepseek-chat&quot;, // 如果使用 DeepSeek，取消此行注释并注释上一行</p><p>&quot;temperature&quot;: 0.7,</p><p>// 强烈建议开启此项，将工具（如文件读写）限制在 workspace 目录内，确保安全</p><p>&quot;tools&quot;: {</p><p>&quot;restrictToWorkspace&quot;: true</p><p>}</p><p>}</p><p>},</p><p>// =======================</p><p>// 3. 聊天渠道配置</p><p>// =======================</p><p>&quot;channels&quot;: {</p><p>// Telegram 机器人配置</p><p>&quot;telegram&quot;: {</p><p>&quot;enabled&quot;: true,</p><p>// 从 @BotFather 获取的 Token</p><p>&quot;token&quot;: &quot;&lt;&lt;YOUR_TELEGRAM_BOT_TOKEN&gt;&gt;&quot;,</p><p>// 用户 ID 白名单，为空则允许所有人，建议填写您的 Telegram 用户 ID</p><p>&quot;allowFrom&quot;: [&quot;&lt;&lt;YOUR_TELEGRAM_USER_ID&gt;&gt;&quot;]</p><p>},</p><p>// 电子邮件收发配置</p><p>&quot;email&quot;: {</p><p>&quot;enabled&quot;: true,</p><p>// 同意邮箱访问协议，必须为 true 才能正常收发邮件</p><p>&quot;consentGranted&quot;: true,</p><p>// IMAP 服务器配置（用于接收邮件）</p><p>&quot;imapHost&quot;: &quot;<a target="_blank" rel="noopener noreferrer nofollow" href="http://imap.gmail.com">imap.gmail.com</a>&quot;, // 例如 Gmail，其他邮箱请自行修改</p><p>&quot;imapPort&quot;: 993,</p><p>&quot;imapUsername&quot;: &quot;<a target="_blank" rel="noopener noreferrer nofollow" href="mailto:your.email@gmail.com">your.email@gmail.com</a>&quot;,</p><p>// 建议使用“应用专用密码”，而非您的邮箱登录密码</p><p>&quot;imapPassword&quot;: &quot;&lt;&lt;YOUR_EMAIL_APP_PASSWORD&gt;&gt;&quot;,</p><p>// SMTP 服务器配置（用于发送回复邮件）</p><p>&quot;smtpHost&quot;: &quot;<a target="_blank" rel="noopener noreferrer nofollow" href="http://smtp.gmail.com">smtp.gmail.com</a>&quot;,</p><p>&quot;smtpPort&quot;: 587,</p><p>&quot;smtpUsername&quot;: &quot;<a target="_blank" rel="noopener noreferrer nofollow" href="mailto:your.email@gmail.com">your.email@gmail.com</a>&quot;,</p><p>&quot;smtpPassword&quot;: &quot;&lt;&lt;YOUR_EMAIL_APP_PASSWORD&gt;&gt;&quot;,</p><p>// 发送邮件时显示的发件人地址</p><p>&quot;fromAddress&quot;: &quot;<a target="_blank" rel="noopener noreferrer nofollow" href="mailto:your.email@gmail.com">your.email@gmail.com</a>&quot;,</p><p>// 允许发邮件给您的发件人白名单，为空则接受所有邮件</p><p>&quot;allowFrom&quot;: [&quot;&lt;&lt;YOUR_TRUSTED_SENDER_EMAIL&gt;&gt;&quot;]</p><p>}</p><p>},</p><p>// =======================</p><p>// 4. 网关服务配置</p><p>// =======================</p><p>&quot;gateway&quot;: {</p><p>// 网关服务监听地址，默认即可，用于管理消息收发</p><p>&quot;host&quot;: &quot;0.0.0.0&quot;,</p><p>&quot;port&quot;: 18790</p><p>},</p><p>// =======================</p><p>// 5. 工具安全配置</p><p>// =======================</p><p>&quot;tools&quot;: {</p><p>// 全局限制所有工具只能在 workspace 目录下操作，防止系统文件被修改</p><p>&quot;restrictToWorkspace&quot;: true</p><p>}</p><p>}</p><p>```</p><p>---</p><p>### 配置详解</p><p>#### 1. <code>providers</code> (LLM 提供方配置)</p><p>这是您的机器人“大脑”的来源。您至少需要配置一个提供商。</p><p>- *<code>openrouter</code>**: 这是一个聚合 API，通过一个 key 访问多种模型（如 Claude, GPT, Gemini 等）。您需要在 [OpenRouter](<a target="_blank" rel="noopener noreferrer nofollow" href="https://openrouter.ai/">https://openrouter.ai/</a>) 注册并获取 API Key。</p><p>- *<code>deepseek</code>**: 这是一个直接 API 配置示例，展示如何连接到特定模型提供商（如 DeepSeek）。如果您使用其他提供商（如 OpenAI），可以类似地添加配置块。</p><p>- *<code>apiKey</code>**: <strong>敏感信息</strong>，请务必妥善保管。您也可以通过设置环境变量 <code>NANOBOT_PROVIDERS_OPENROUTER_APIKEY</code> 来注入，避免写入配置文件。</p><p>#### 2. <code>agents</code> (Agent 默认行为配置)</p><p>这里定义了机器人的默认工作方式。</p><p>- *<code>model</code>**: 指定默认使用的模型。如果配置了多个 <code>providers</code>，nanobot 会根据模型名称自动匹配对应的提供商。例如<code>anthropic/...</code> 会通过 OpenRouter 路由，而 <code>deepseek-chat</code> 会通过 <code>deepseek</code> 提供商。</p><p>- *<code>tools.restrictToWorkspace</code>**: <strong>安全关键</strong>。设置为 <code>true</code> 后，机器人所有的文件操作工具都会被限制在 <code>~/.nanobot/workspace/</code> 目录内，防止其误操作或恶意修改您系统上的其他文件。</p><p>#### 3. <code>channels</code> (聊天渠道配置) - 您的核心需求</p><p>这是连接用户与机器人的桥梁。</p><p><strong>Telegram 配置</strong>：</p><p>- *<code>enabled</code>**: 设置为 <code>true</code> 以启用此渠道。</p><p>- *<code>token</code>**: 您的 Telegram Bot Token。您需要在 Telegram 中与 [@BotFather](<a target="_blank" rel="noopener noreferrer nofollow" href="https://t.me/botfather">https://t.me/botfather</a>) 对话，按照 <code>/newbot</code> 指令创建一个机器人并获取 Token。</p><p>- *<code>allowFrom</code>**: <strong>安全白名单</strong>。填写您的 Telegram 用户 ID（可以通过 [@userinfobot](<a target="_blank" rel="noopener noreferrer nofollow" href="https://t.me/userinfobot">https://t.me/userinfobot</a>) 获取）。这样设置后，**只有您**能与这个机器人对话，防止他人滥用。如果想公开使用，可以将其留空 <code>[]</code>。</p><p><strong>Email 配置</strong>：</p><p>- *<code>enabled</code>**: 设置为 <code>true</code> 以启用此渠道。</p><p>- *<code>consentGranted</code>**: 必须设置为 <code>true</code>，表示您授权机器人访问您的邮箱收发邮件。</p><p>- *<code>imap*</code> / <code>smtp*</code>**: 分别是接收和发送邮件的服务器设置。以上示例是 Gmail 的配置，如果您使用其他邮箱服务（如 Outlook, QQ邮箱等），请查询并修改相应的服务器地址、端口。</p><p>- *<code>imapPassword</code> / <code>smtpPassword</code>**: <strong>安全建议</strong>。对于 Gmail 等现代邮箱服务，不应使用您的账户登录密码，而应为其生成一个**应用专用密码**，并在邮箱设置中开启 IMAP/SMTP 服务。</p><p>- *<code>fromAddress</code>**: 机器人回复邮件时，将显示的发件人地址。</p><p>- *<code>allowFrom</code>**: 邮件发件人白名单。只有在这个列表中的邮箱发来的邮件，机器人才会处理。如果留空 <code>[]</code>，则会处理所有收到的邮件。</p><p>#### 4. <code>gateway</code> (网关服务配置)</p><p>- 当您运行 <code>nanobot gateway</code> 命令时，会启动这个服务。它负责监听所有已启用的渠道（本例中是 Telegram 和 Email），并将消息统一路由给 AI Agent 处理。通常保持默认配置即可。</p><p>#### 5. <code>tools</code> (工具安全配置)</p><p>- 这是一个全局设置，与 <code>agents.defaults.tools.restrictToWorkspace</code> 功能类似，确保所有工具的执行都在安全沙盒内。双重保险，建议开启。</p><p>### 使用步骤简述</p><p>1. <strong>创建配置文件</strong>: 按照上述示例，将您的真实信息填入，并保存为 <code>~/.nanobot/config.json</code>。</p><p>2. <strong>启动网关</strong>: 在终端中运行 <code>nanobot gateway</code>。</p><p>3. <strong>开始使用</strong>:</p><p>* 在 Telegram 中找到您创建的机器人，发送消息。</p><p>* 向您配置的邮箱地址发送一封邮件。</p><p>机器人将根据您的配置，通过相应的渠道回复您。如果您是第一次使用，建议先只用 Telegram 渠道进行测试，确保工作正常后再配置 Email 渠道。</p><p></p><h3 level="3" id="Nvidia-api">Nvidia api</h3><p>大模型配置</p><div class="llt-code readonly"><div class="language">vbnet</div><div class="wrapper"><pre><code><span class="hljs-string" class="hljs-string">&quot;providers&quot;</span>: {
        <span class="hljs-string" class="hljs-string">&quot;openai&quot;</span>: {
            <span class="hljs-string" class="hljs-string">&quot;apiKey&quot;</span>: <span class="hljs-string" class="hljs-string">&quot;nvapi-vCqKOJQgt237*&quot;</span>,
            <span class="hljs-string" class="hljs-string">&quot;baseUrl&quot;</span>: <span class="hljs-string" class="hljs-string">&quot;https://integrate.api.nvidia.com/v1&quot;</span>
        }
    },
    <span class="hljs-string" class="hljs-string">&quot;agents&quot;</span>: {
        <span class="hljs-string" class="hljs-string">&quot;defaults&quot;</span>: {
            <span class="hljs-string" class="hljs-string">&quot;model&quot;</span>: <span class="hljs-string" class="hljs-string">&quot;nvidia/openai/gpt-oss-120b&quot;</span>,
            <span class="hljs-string" class="hljs-string">&quot;temperature&quot;</span>: <span class="hljs-number" class="hljs-number">0.6</span>,
            <span class="hljs-string" class="hljs-string">&quot;max_tokens&quot;</span>: <span class="hljs-number" class="hljs-number">256</span>
        }
    },

<span class="hljs-keyword" class="hljs-keyword">error</span> ╭─ 🐈 nanobot ───────────────────────────────────────────╮
│ <span class="hljs-keyword" class="hljs-keyword">Error</span> calling LLM: litellm.BadRequestError: LLM        │
│ Provider <span class="hljs-built_in" class="hljs-built_in">NOT</span> provided. Pass <span class="hljs-keyword" class="hljs-keyword">in</span> the LLM provider you    │
│ are trying <span class="hljs-keyword" class="hljs-keyword">to</span> <span class="hljs-keyword" class="hljs-keyword">call</span>. You passed                         │
│ model=nvidia/openai/gpt-oss-<span class="hljs-number" class="hljs-number">120</span>b Pass model <span class="hljs-keyword" class="hljs-keyword">as</span> E.g.    │
│ <span class="hljs-keyword" class="hljs-keyword">For</span> <span class="hljs-comment" class="hljs-comment">&apos;Huggingface&apos; inference endpoints pass in          │</span>
│ completion(model=<span class="hljs-comment" class="hljs-comment">&apos;huggingface/starcoder&apos;,..) Learn     │</span>
│ more: https://docs.litellm.ai/docs/providers</code></pre></div></div><p>默认模型那个地方这么改<br>”&quot;agents&quot;: {<br>&quot;defaults&quot;: {<br>&quot;workspace&quot;: &quot;~/.nanobot/workspace&quot;,<br>&quot;model&quot;: &quot;openai/minimaxai/minimax-m2.1&quot;,<br>...<br>}<br>},</p><p>主要就是” &quot;model&quot;: &quot;openai/minimaxai/minimax-m2.1&quot;,“</p><p>这个方式是正确的，模型添加openai前缀即可</p><p></p><p></p><script type="module">const injectHtml = (root, html) => {
  const iframe = document.createElement("iframe");
  const htmlContent = `<html><head></head><body>${html}</body></html>`;
  iframe.style.width = "100%";
  iframe.style.height = "100%";
  iframe.onload = () => {
    const doc = iframe.contentDocument || iframe.contentWindow?.document;
    if (!doc) {
      return;
    }
    doc.open();
    doc.write(htmlContent);
    doc.close();
  };
  root.replaceChildren(iframe);
}
  document.querySelectorAll('.playground')?.forEach(el=>{
    const html = el.getAttribute('data-html');
    if (html) {
      injectHtml(el,html);
    }
    const indicator = document.createElement("div");
    indicator.className = "indicator";
    const showCode = document.createElement("div");
    showCode.className = "show-code";
    showCode.innerText = "code";
    showCode.onclick = () => {
      el.parentElement.classList.remove("preview-only");
    };
    const showPreview = document.createElement("div");
    showPreview.className = "show-preview";
    showPreview.innerText = "preview";
    showPreview.onclick = () => {
      el.parentElement.classList.add("preview-only");
    };
    indicator.appendChild(showCode);
    indicator.appendChild(showPreview);
    el.parentElement.appendChild(indicator);
    if (window.screen.width < 768) {
      showPreview.click();
    }
  });</script></div> <div data-page-id="stepbystep-configuration-guide-for-nanobot-" class="navigator flex justify-between items-center mt-4 py-4"> <a href="/post/glm5" class="flex items-center gap-1 text-blue cursor-pointer flex-[45%]"> <div class="i-ri:arrow-left-double-line w-5 h-5 flex-shrink-0"></div> <div class="text-start">glm5</div> </a> <a href="/post/糖醋里脊" class="flex items-center justify-end gap-1 text-blue cursor-pointer flex-[45%]"> <div class="text-end">糖醋里脊</div> <div class="i-ri:arrow-right-double-line w-5 h-5 flex-shrink-0"></div> </a> </div> </div> <div class="outline-wrapper"></div> </main>  <footer class="site-footer" data-astro-cid-sz7xmlte> <!-- 导航链接 --> <nav class="footer-nav" data-astro-cid-sz7xmlte>  <a href="/" class="footer-link" data-astro-cid-sz7xmlte> Home </a> <span class="nav-dot" data-astro-cid-sz7xmlte>·</span> <a href="/tag/projects" class="footer-link" data-astro-cid-sz7xmlte> Projects </a> <span class="nav-dot" data-astro-cid-sz7xmlte>·</span> <a href="/tools" class="footer-link" data-astro-cid-sz7xmlte> Notes </a> <span class="nav-dot" data-astro-cid-sz7xmlte>·</span> <a href="https://web.chatboxai.app/" class="footer-link" target="_blank" rel="noopener noreferrer" data-astro-cid-sz7xmlte> Chatbox </a> <span class="nav-dot" data-astro-cid-sz7xmlte>·</span> <a href="/about" class="footer-link" data-astro-cid-sz7xmlte> About </a>  </nav> <!-- 分割线 --> <div class="footer-divider" data-astro-cid-sz7xmlte></div> <!-- 版权信息 --> <div class="footer-copyright" data-astro-cid-sz7xmlte> <a href="https://isharebox.github.io" data-astro-cid-sz7xmlte>©  isharebox  ·  since 2026    ·</a> <a href="/rss.xml" class="rss-link" target="_blank" rel="noopener noreferrer" title="RSS Feed" data-astro-cid-sz7xmlte> <svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 256 256" aria-label="RSS Feed" data-astro-cid-sz7xmlte> <rect width="256" height="256" rx="28" fill="#ff6b35" data-astro-cid-sz7xmlte></rect> <circle cx="68" cy="189" r="24" fill="#fff" data-astro-cid-sz7xmlte></circle> <path d="M160 213h-34a82 82 0 0 0-82-82v-34a116 116 0 0 1 116 116z" fill="#fff" data-astro-cid-sz7xmlte></path> <path d="M184 213A140 140 0 0 0 44 73V38a175 175 0 0 1 175 175z" fill="#fff" data-astro-cid-sz7xmlte></path> </svg> </a> </div> </footer>  <!-- ★ 添加回到顶部按钮组件 --> <button id="back-to-top" class="back-to-top" aria-label="Back to top" data-astro-cid-wlspcwf4> <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" data-astro-cid-wlspcwf4> <path d="M18 15l-6-6-6 6" data-astro-cid-wlspcwf4></path> </svg> </button>   </body></html>